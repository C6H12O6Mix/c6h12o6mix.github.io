[{"categories":["Technology"],"content":"StableDiffusion之秋叶整合包的探索之旅 ","date":"2024-07-10","objectID":"/stablediffusion%E4%B9%8B%E7%A7%8B%E5%8F%B6%E6%95%B4%E5%90%88%E5%8C%85%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B9%8B%E6%97%85/:1:0","tags":["StableDiffusion"],"title":"StableDiffusion之秋叶整合包的探索之旅","uri":"/stablediffusion%E4%B9%8B%E7%A7%8B%E5%8F%B6%E6%95%B4%E5%90%88%E5%8C%85%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B9%8B%E6%97%85/"},{"categories":["Technology"],"content":"1. 前言 为了确保AI绘画的流畅体验，推荐设备上安装有 Nvidia 独立显卡。显存至少需达到6GB，以满足基本的出图需求；若要进行 AI 训练，则建议显存在12GB以上。显卡型号方面，RTX40 系列是首选，至少也要达到 RTX30 系列的标准。 若您手头没有N卡，虽然可以利用CPU进行图形处理，但效率相对较低，出图速度也会受到影响。此外，为了支持高效的AI绘画工作，CPU性能也需强劲，并且至少配备16GB内存。 简而言之，对于简单的图形处理或初步体验，CPU或许足够。然而，若您追求专业的AI绘画效果，N卡搭配高性能CPU和充足内存才是理想的选择。 ","date":"2024-07-10","objectID":"/stablediffusion%E4%B9%8B%E7%A7%8B%E5%8F%B6%E6%95%B4%E5%90%88%E5%8C%85%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B9%8B%E6%97%85/:1:1","tags":["StableDiffusion"],"title":"StableDiffusion之秋叶整合包的探索之旅","uri":"/stablediffusion%E4%B9%8B%E7%A7%8B%E5%8F%B6%E6%95%B4%E5%90%88%E5%8C%85%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B9%8B%E6%97%85/"},{"categories":["Technology"],"content":"2. 安装与配置 1. 查看显卡型号 打开设备管理器，找到显示适配器，可以看到设备具体的显卡型号 img-2.1 2. 依赖\u0026安装包下载 如果设备是首次安装，需要下载启动依赖 windowsdesktop-run-time-6.0.25-win-x64.exe，安装依赖后，再解压 sd-webui-aki-v4.8.7z 压缩包。 img-2.2 3. 启动器配置 1）打开启动器 解压得到 sd-webui-aki-v4.8 后，打开 A绘世启动器.exe img-2.3 2）更改配置模式 打开启动器后，进入 设置 界面，将配置模式设置为专家（可以根据个人习惯修改语言设置）。 img-2.4 3）切换分支 进入版本管理，可以根据自己的生成引擎（显卡或CPU）来选择不同分支，由于博主设备使用 CPU 参与计算，分支选择 lshqqytiger/stable-diffusion-webui-directml-主线。 img-2.5 4）更新分支 切换分支后，启动器提示分支切换成功，请刷新列表，一键更新后重启启动器，点击确定。然后点击启动器的刷新列表和一键更新按钮。接着重新打开启动器可以发现已经切换到了最新版本 ee49046。 img-2.6 5）高级选项 进入高级选项界面，根据自身设备选择生成引擎。如果是显卡参与计算的话，建议根据显卡规格设置显存优化。 img-2.7 6）环境维护 根据生成引擎，安装特定版本的 PyTorch 和 xFormers img-2.8 ","date":"2024-07-10","objectID":"/stablediffusion%E4%B9%8B%E7%A7%8B%E5%8F%B6%E6%95%B4%E5%90%88%E5%8C%85%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B9%8B%E6%97%85/:1:2","tags":["StableDiffusion"],"title":"StableDiffusion之秋叶整合包的探索之旅","uri":"/stablediffusion%E4%B9%8B%E7%A7%8B%E5%8F%B6%E6%95%B4%E5%90%88%E5%8C%85%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B9%8B%E6%97%85/"},{"categories":["Technology"],"content":"3. 一键启动 1. 准备启动 进入启动界面，点击一键启动按钮 img-3.1 2. 安装组件 启动过程中可能遇到缺少 module 的情况，如 ModuleNotFoundError: No module named 'optimum' 此时复制 optimum，进入环境维护界面，点击重装单个 Python 组件，将 optimum 粘贴到 Pip 软件包名称 对应的文本框，点击 重新安装。 img-3.2 3. 启动成功 上述初步配置的步骤全部完成后，会在网页启动程序，其默认端口为 7860 img-3.3 ","date":"2024-07-10","objectID":"/stablediffusion%E4%B9%8B%E7%A7%8B%E5%8F%B6%E6%95%B4%E5%90%88%E5%8C%85%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B9%8B%E6%97%85/:1:3","tags":["StableDiffusion"],"title":"StableDiffusion之秋叶整合包的探索之旅","uri":"/stablediffusion%E4%B9%8B%E7%A7%8B%E5%8F%B6%E6%95%B4%E5%90%88%E5%8C%85%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B9%8B%E6%97%85/"},{"categories":["Technology"],"content":"4. 插件 ","date":"2024-07-10","objectID":"/stablediffusion%E4%B9%8B%E7%A7%8B%E5%8F%B6%E6%95%B4%E5%90%88%E5%8C%85%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B9%8B%E6%97%85/:1:4","tags":["StableDiffusion"],"title":"StableDiffusion之秋叶整合包的探索之旅","uri":"/stablediffusion%E4%B9%8B%E7%A7%8B%E5%8F%B6%E6%95%B4%E5%90%88%E5%8C%85%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B9%8B%E6%97%85/"},{"categories":["Work"],"content":"Java 后端初步学习 ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:1:0","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"一、基础核心 ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:2:0","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"1. 线程 1.1 java 线程创建方式 1) 继承 Thread 类 重写的是 run() 方法，而不是 start() 方法，但是占用了继承的名额，Java 中的类是单继承的 public class ThreadImpl extends Thread { public static void main(String[] args) { ThreadImpl thread = new Thread(); thread.start(); } @Override public void run() { System.out.println(\"hello world!\") } } 2) 实现 Runnable 接口 利用接口的多继承特性，创建线程，实现 run() 方法 public class ThreadImpl implements Runnnable { public static void main(String[] args) { Thread thread = new Thread(new ThreadImpl()); thread.start(); } public void run() { System.out.println(\"hello world!\"); } } 3) 实现 Callable 接口 上述两种方法均不能实现 run() 方法返回值，而实现 Callable 接口中的 call() 方法 (需要 Tread + Future 配合) ，支持拿到异步执行任务的结果 public class ThreadImpl implements Callable\u003cString\u003e { public static void main(Sting[] args) { FutureTask\u003cString\u003e futureTask = new FutureTask\u003c\u003e(new ThreadImpl()); Thread thread = new Thread(futureTask); thread.start(); String result = futureTask.get(); System.out.println(result); } public String call() { return \"hello world!\"; } } 4) 利用线程池来创建线程 此方法通过实现 Callable 接口或是 Runnable 接口均可，由 ExecutorService 来创建线程 public class ThreadImpl implements Runnable { public static void main(String[] args) throws ExecutionException { ExcutorService executorService = Executors.newFixedThreadPool(10); executorService.execute(new ThreadImpl()); } public void run() { System.out.println(\"hello world!\"); } } 总结 以上四种方法的底层都是基于 Runnable 1.2 为什么不建议使用 Executors 来创建线程池 1. FixedThreadPool 当我们使用 Executors 创建 FixedThreadPool 时，对应的构造方法为： public static ExecutorService new FixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u003cRunnable\u003e()); } 发现创建的队列为 LinkedBlockingQueue，是一个无界阻塞队列。 假设使用该方法创建 nThread=10 线程池执行任务，遇到任务过多的情况就会不断添加到队列中，最终导致内存溢出 OOM。 2. SingleThreadExecutor 当我们使用 Excutors 创建 SingleTheadExcutor 时，对应的构造方法为： public static ExecutorService new SingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExcutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u003cRunnable\u003e())); } 1.3 线程池的状态 img-1.1 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, wc: 0)); private static final int COUNT_BITS = Interger.SIZE - 3; private static final int CAPACITY = (1 \u003c\u003c COUNT_BITS) - 1; // runState is stored in the high-order bits private static final int RUNNING = -1 \u003c\u003c COUNT_BITS; private static final int SHUTDOWN = 0 \u003c\u003c COUNT_BITS; private static final int STOP = 1 \u003c\u003c COUNT_BITS; private static final int TIDYING = 2 \u003c\u003c COUNT_BITS; private static final int TERMINATED = 3 \u003c\u003c COUNT_BITS; // Packing and unpacking ctl private static int runStateOf(int c) {return c \u0026 ~CAPACITY;} private static int workerCountOf(int c) {return c \u0026 CAPACITY;} private static int ctlOf(int rs, int wc) {return rs | wc;} ctl 作为一个 4 字节的整型变量，32 位 bit 位，高 3 位用来存储线程池的状态 RUNNING、SHUTDOWN、STOP、TIDYING、TERMINATED。剩下的 29 位用来存储线程池数量。 1.4 Sychronized 和 ReentrantLock 有哪些不同点？ Sychronized ReentrantLock Java 中的一个关键字 JDK 提供的一个类 JVM 层面上的锁 API 层面的锁 自动加锁与释放锁 需要手动加锁与释放锁 不可获取当前线程是否上锁 可获取当前线程是否上锁 isHeldByCurrentThread 非公平锁 公平锁或非公平锁（可通过参数设置） 不可中断 可中断 1. 调用设置超时方法 tryLock(long timeout, timeUnit unit) 2. 调用 lockInterruptibly() 放到代码块中，然后调用 interrupt() 方法可以中断 锁的是对象，锁信息保存在对象头中 int 类型的 state 标识来标识锁的状态 底层有锁升级过程 没有锁升级过程 1.5 ThreadLoal 有哪些应用场景？它的底层如何实现？ 1. ThreadLocal 机制 ThreadLocal 是 Java 中所提供的线程本地存储机制，可以利用该机制将数据缓存在某个线程内部，该线程可以在任意时刻、任意方法中获取缓存中的数据。 img-1.2 2. ThreadLocal 和 ThreadLocalMap ThreadLocal 底层是通过 ThreadLocalMap 来实现的，每个 Thread 对象中都存在一个 ThreadLocalMap，Map 的 key 为 ThreadLocal 对象，Map 的 value 为需要的缓存值。 /* ThreadLocal values pertaining to this thread. This map is maintained by the ThreadLocal Class.*/ ThreadLocal.ThreadLocalMap threadLocals = null; 3. ThreadLocal 存在的局限 如果在线程池中使用 ThreadLocal 会造成内存泄露，因为当 ThreadLocal 对象使用完之后，应该要把设置的 key，value，也就是 Entry 对象进行回收。但线程池中的线程本身不会被不会回收，而线程对象是通过强引用指向 ThreadLocalMap，ThreadLocalMap 也是通过强引用指向 Entry 对象，线程不被回收，导致强引用的数据不会被垃圾回收，从而出现内存泄漏。 解决办法是，在使用了 ThreadLocal 对象之后，手动调动 ThreadLocal 的 remove 方法，手动清除 Entry 对象。 4. ThreadLocal 的应用场景 当一","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:2:1","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"2. 虚拟机 2.1 虚拟机结构 1. 类加载器 1) 类加载器的类别 **启动类加载器：**负责加载 Java 核心类，它是 Java 虚拟机的一部分，负责最基础和最核心的类加载任务。 **扩展类加载器：**用于 Java 扩展目录的类，它扩展了 Java 的核心功能，允许开发人员和第三方供应商提供额外的类库。 **应用程序类加载器：**加载我们自己编写的 Java 类，负责加载应用程序的类路径上的类。 2) 类加载机制有两种主要的委派机制 **双亲委派机制：**当一个类加载器收到加载类的请求时，它会先委托给父加载器去加载。这种机制保证了类加载的顺序和一致性，避免重复加载。例如，应用程序类加载器加载一个类时，会先委托给扩展类加载器，然后扩展类加载器再委托给启动类加载器，直到核心类库，如果找不到则返回到应用程序类加载器。 **全盘负责委托机制：**在这种机制下，当一个类加载器负责加载某个类时，它会负责加载该类的所有依赖。如果没有显式指定使用另一个加载器，当前加载器会尝试加载所有相关的类。这种方式相对简单直接，但可能导致类冲突和资源浪费。 2. 堆存储类变量，当栈需要调用类变量时，栈中局部变量表存储的类变量指针会指向堆的类变量。 3. 栈存储局部变量表、操作数栈、动态链接、方法出口等 4. 方法区/原空间存储常量、静态变量、类信息（若静态变量等也是类变量，那么方法区也将存放的是类变量的指针，指向堆中的类变量） img-1.1 2.2 栈 public class Demo { public int test() { int a = 1; int b = 2; int c = a + b; return c; } public static void main(String[] args) throws IOException { Demo demo = new Demo(); demo.test(); System.out.println(\"end\"); } } 针对上述程序，其栈存储下图所示： img-1.2 2.3 JVM 参数 假设我们有一个亿级流量电商的网站，其中日活用户 500 万，日均 50 万单。在日常情况下，订单为每秒几十单，但是遇到平台商家的大促活动时，订单可达每秒 1000 多单，假设订单平均分摊在 4 核 8 G 的服务器上，这时候很容易产生内存溢出 OOM 的情况。 假定每个订单对象的大小为 1KB，每秒就是 300KB 订单对象生成，下单还涉及其他对象和操作，综合下来每秒就是 60 MB 大小的对象，在一秒后都变成垃圾对象。 img-1.3 具体的运行时数据区的内存模型如下，线程每秒产生 60MB 对象，运行十四秒就将占满 enden 区，出发 minor gc 进行垃圾回收处理。但是运行 minor gc 时，某线程有可能还在执行，并且其指向 enden 区的对象，这时 minor gc 不会清理线程指向的对象，而是把对象传递到 Survivor 区，甚至有可能直接传递到老年区（60MB 大于 Survivor 区 100 MB * 1/2，会直接传递到老年代）。 不出几分钟，存活期理应只有 1 秒的对象，就会填满老年区，导致内存溢出触发 full gc。 可以通过，调整老年代和新生代的内存规模： enden S0 S1 Tenured 800M -\u003e 1.6G 100M -\u003e 200M 100M -\u003e 200M 2G -\u003e 1G img-1.4 ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:2:2","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"3. GC 算法 GC 是 JVM 自动内存管理 的重要组成部分。主要包括标记-清除、标记-整理、复制算法和分代收集算法。 **标记-清除算法：**分为两个阶段，首先标记所有需要回收的对象，然后统一回收所有被标记的对象。它是最基础的收集算法。 **标记-整理算法：**与标记-清除算法类似，首先进行标记阶段，在清理阶段不是简单地回收对象，而是让所有存活的对象向一端移动，然后直接清理掉边界以外的内存。这样可以减少内存碎片化。 复制算法：这种算法将内存分为两块大小相等的区域，每次只使用其中的一块。当一块内存区域的对象存活时间结束时，将存活的对象复制到另一块区域中，然后清理掉该块区域。这样做的好处是每次回收时只需对其中一半的内存空间进行操作，减少了碎片化问题。 3.1 为什么使用 GC 堆内存在 Java 等编程语言中是一种重要的内存区域，用于存储对象示例和数组。堆内存的结构通常包括以下几个关键部分： **新生代（Young Generation）：**新创建的对象首先会被分配到新生代中。新生代通常被进一步分为 Eden 空间和两个 Survivor 空间（通常称为 From 和 To 区或者 S0 和 S1 区）。大多数对象在新生代中很快变得不可达并被垃圾回收器收集。 **老年代（Old Generation）：**新生代中新生代中经历多次垃圾回收仍然存活的对象会被移动到老年代。老年代用于存储生命周期较长的对象，通常会被更慎重地回收。 **永久代（或原空间，Permanent Genration / Metaspace）**在较早版本的 Java 中存在永久代，用于存储类的元数据、常量池等。在现代的 Java 版本中，永久代被元空间（Metaspace）取代，元空间使用本地内存来存储这些数据，因此不再有固定大小的限制，而且垃圾收集的方式也不同于堆内存。 img-1.3 3.2 垃圾回收器 JVM提供了多种垃圾回收器，包括 Serial、ParNew、Parallel Scavenge、Serial Old、Parallel Old、CMS 和 G1 等。每种收集器适用于不同的应用场景，开发者可以根据应用特点选择合适的垃圾回收器。 1. Serial 收集器 Serial 收集器通过复制算法来处理新生代，而老年代则使用标记-整理算法。该收集器利用单线程进行垃圾回收，因此在回收过程中会直接中断所有程序线程，实施全局停顿（Stop-The-World）。 2. ParNew 收集器 ParNew 收集器主要用于新生代，采用复制算法进行垃圾回收，而老年代则使用标记-整理算法。它利用多线程来处理垃圾回收，在进行回收时，应用程序仍会经历中断。 3. Parrallel Scavenge 收集器 Parrallel Scavenge 收集器专为吞吐量优先的应用程序设计，其新生代采用复制算法进行垃圾回收，而老年代采用标记-整理算法。与 ParNew 收集器相似，也是利用多线程来处理垃圾回收工作。 Serial Old 收集器和 Parallel Old 收集器分别是 Serial 收集器和 Parallel Scavenge 收集器的老年代版本。它们可以看作是将老年代的垃圾回收算法单独提取出来，以便于其他收集器的新生代部分组合使用。 4. CMS 收集器 CMS 收集器 （Concurrent Mark-Sweep 收集器）在启动垃圾回收时，首先快速获取于根节点直接相连的对象，因此停顿时间比较短。随后，它与应用程序竞争 CPU 资源，进行并发标记阶段，识别仍然可达的对象。随着并发标记的进行，新生成的对象会在后续的短暂停顿期间被标记。最终，在清理阶段，CMS 收集器会清理那些没有被标记的空间内存。 img-1.4 5. G1 收集器 G1 收集器将 Java 堆划分为多个大小相等的独立区域（Region）。虽然保留了新生代和老年代的概念。但它们不再是物理上的隔离，而是由许多可能并不连续的 Region 组成的集合。G1 收集器允许大对象直接分配到 Humongous 区域，这些区域专门用于存放短期的巨型对象，避免了因为无法找到连续空间而提前出发下一次GC，从而减少了 Full GC 所带来的大量开销。 在 G1 收集器中，除了将 Java 堆划分为多个大小相等的独立区域（Region）外，还实现了筛选回收的过程。用户可以指定回收时间，因此 JVM 会评估回收成本并制定回收计划，以优先回收堆系统性能影响较大的对象。 ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:2:3","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"4. Tomcat 4.1 Tomcat 中为什么要使用自定义类加载器 一个 Tomcat 中可以部署多个应用，而每个应用中都存在很多类，并且各个应用中的类是独立的，全类名是可以相同的，比如一个订单系统中可能存在 com.demo.User 类，一个库存系统中可能也存在 com.demo.User 类。 一个 Tomcat，不管内部部署了多少个应用，Tomcat 启动之后就是一个 Java 进程，也就是 JVM，所以如果 Tomcat 中只存在一个类加载器，比如默认的 AppClassLoader，那么就只能加载一个 com.demo.User 类，这是有问题的。 而在 Tomcat 中，会为部署的每个应用都生成一个类加载器实例，名字叫做 WebAppClassLoader，这样 Tomcat 中每个应用就可以使用自己的类加载器去加载自己的类，从而达到应用之间的类隔离，不出现冲突。另外 Tomcat 还利用自定义加载器实现了热加载功能。 ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:2:4","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"5. Java 基础面试 16 问 1. 进程和线程的区别 进程是程序的一次执行，是系统进行资源分配和调度的独立单位，他的作用是使程序能够并发执行提高资源利用率和吞吐率。 由于进程是资源分配和调度的基本单位，且进程的创建、销毁、切换会产生大量的时、空开销。故提出线程概念，线程是比进程更小的，并能独立运行的基本单位。他是进程的一个实体，可以减少程序并发执行时的开销，使得操作系统具有更好的并发性。 线程基本不拥有系统资源，只有一些运行时必不可少的资源，比如程序计数器、寄存器和栈，进程则占有堆、栈。 2. synchronized 原理 synchronized 是 java 提供的原子性内置锁，这种内置的且透明的锁也被称为监视器锁，使用 synchronized 之后，会在编译之后在同步的代码块前后加上 monitorenter 和 monitorexit 字节码指令，他依赖操作系统底层互斥锁实现。他的作用主要就是实现原子性操作和解决共享变量的内存可见性问题。 synchronized 的具体实现流程： 执行 monitorenter 指令时会尝试获取对象锁，如果对象没有被锁定或者已经获得了锁，锁的计数器 + 1。此时其他竞争锁的线程则会进入等待队列中。 执行 monitorexit 指令时则会把计数器 - 1，当计数器值为 0 时，则锁释放，处于等待队列中的线程再继续竞争锁。 synchronized 是排它锁，当一个线程获得锁之后，其他线程必须等待该线程释放锁后才能获得锁，而且由于 Java 中的线程和操作系统原生线程是一一对应的，线程被阻塞或者唤醒时会从用户态切换到内核态，这种转换非常消耗性能。 从内存语义来说，加锁的过程会清除工作内存中的共享变量，再从主内存读取，而释放锁的过程则是将工作内存中的共享变量写回主内存。 如果再深入到源码来说，synchronized 实际上有两个队列 waitSet 和 entryList 当多个线程进入同步代码块时，首先进入 entryList 有一个线程获取到 monitor 锁后，就将自己赋值给当前线程，并使得计数器 + 1 如果线程调用 wait 方法，将释放锁，当前线程置为 null，计数器 - 1，同时进入 waitSet 等待被唤醒，调用 notify 或者 notifyAll 之后有会进入 entryList 竞争锁 如果线程执行完毕，同样释放锁，计数器 - 1，当前线程置为 null img-1.1 2. 锁的优化机制 优化机制包括自适应锁、自旋锁、锁消除、锁粗化、轻量级锁和偏向锁。 锁的状态从低到高依次为无锁-\u003e偏向锁-\u003e轻量级锁-\u003e重量级锁，升级的过程就是从低到高，降级在一定条件也是有可能发生的。 1）自旋锁： 由于大部分时候，锁以及共享变量被占有的时间非常短，所有没有必要挂起线程。自旋锁的核心概念就是当一个线程尝试获取一个已经被其他线程持有的锁时，它不会立即进入睡眠状态，而是在当前位置循环（自旋）等待锁的释放。其主要特点如下： **非阻塞性：**自旋锁不会使线程进入睡眠状态，而是让线程在当前位置循环等待，直到锁被释放。 适用于锁持有时间短的场景：如果锁的持有时间很短，自旋锁可以减少线程从睡眠到唤醒的开销，提高效率。 避免线程切换开销：由于线程不会进入睡眠状态，因此避免了线程切换的开销，这在某些高并发场景下是有利的。 可能导致CPU资源浪费：如果锁被长时间持有，自旋锁会导致等待的线程占用CPU资源进行无意义的循环，从而降低系统的整体性能。 超时机制：自旋锁通常在实现时会有一个超时机制，如果在超时时间内锁没有被释放，线程可以选择放弃自旋，进入睡眠状态，以避免无限期地占用CPU资源 2）自适应锁： 自适应锁就是自适应的自旋锁，自旋的时间不是固定时间，而是由前一次在同一个锁上的自旋时间和锁的持有者状态来决定。 3）锁消除： 锁消除指的是JVM检测到一些同步的代码块，完全不存在数据竞争的场景，也就是不需要加锁，就会进行锁消除。 4）锁粗化： 假设有一个多线程程序，其中多个线程需要频繁访问一个共享数据结构。如果每个线程访问时都使用独立的锁，可能会导致频繁的锁争用和上下文切换。通过锁粗化，可以将这些锁合并为一个更大的锁，使得所有线程在访问数据结构时都使用同一个锁，从而减少锁的争用和上下文切换。锁粗化除了可以通过合并锁，具体还可以通过扩大锁的范围，使得更多的操作在锁的保护下执行，减少锁的获取和释放次数。 5）偏向锁： 当一个线程首次访问同步代码块时，JVM 会将这个锁标记为偏向当前线程，并将线程 ID 记录在对象头中。如果后续访问仍然是同一个线程，那么这个线程不需要进行任何同步操作，直接进入同步代码块，因为 JVM 认为这个线程是这个锁的偏向所有者。若有其他线程尝试访问同一个同步代码块，JVM 会撤销偏向状态，并将锁升级为轻量级乃至重量级锁。其适用场景： 单线程程序：在单线程程序中，偏向锁可以显著提高性能。 低并发多线程程序：在多线程竞争不激烈的情况下，偏向锁可以提高程序的运行效率。 可以通过 JVM 参数来启用或者禁用偏向锁： XX:+UseBiasedLocking：启用偏向锁（默认启用）。 XX:-UseBiasedLocking：禁用偏向锁。 6）轻量级锁 轻量级锁是一种基于 CAS (Compare-And-Swap) 操作的锁机制，它主要用于减少线程在获取锁时的开销。当线程首次访问同步代码块时，JVM 会检查锁对象的 Mark Word（对象头）是否指向当前线程。如果是，表示当前线程已经持有锁，可以直接进入同步代码块。如果不是，JVM 会尝试使用 CAS 操作将锁对象的 Mark Word 替换为当前线程的指针。如果CAS操作成功，表示当前线程成功获取了锁；如果失败，则表示锁已经被其他线程持有。 适用场景： 适用于锁竞争不激烈且线程持有锁的时间较短的场景。 可以减少线程在获取锁时的上下文切换和阻塞。 7）重量级锁 重量级锁是一种基于操作系统互斥量的锁机制。它主要用于处理高并发场景下的锁竞争。当线程尝试获取锁时，如果锁已经被其他线程持有，JVM 会将当前线程阻塞，并将其加入到锁对象的等待队列中。持有锁的线程在释放锁时，会唤醒等待队列中的线程，这些线程会重新尝试获取锁。重量级锁涉及到操作系统层面的线程阻塞和唤醒，因此开销较大。 锁的升级机制 **无锁状态：**初始状态，对象没有被锁定，没有线程进入同步代码块。 **偏向锁：**当线程首次访问同步代码块时，JVM 会将对象头的 Mark Word 标记为偏向当前线程，实现无锁竞争。、 轻量级锁：如果多个线程尝试访问同一个同步代码块，JVM 会撤销偏向锁，将对象头复制到当前线程的栈中，并尝试使用 CAS 操作将对象头指向栈中的锁记录，实现轻量级锁。 重量级锁：如果轻量级锁状态下发生严重的锁竞争，或者锁被长时间持有，JVM 会将轻量级锁升级为重量级锁，此时涉及到操作系统层面的线程阻塞和唤醒。 锁升级条件 多个线程竞争：当多个线程尝试获取同一个锁时，JVM 会考虑升级锁的状态。 自旋失败：在轻量级锁状态下，如果 CAS 操作尝试失败，JVM 会进行一定次数的自旋，如果自旋后仍然无法获取锁，JVM 会考虑升级锁。 长时间持有：如果锁被长时间持有，JVM会认为轻量级锁无法满足当前的并发需求，从而升级为重量级锁。 锁升级流程图 img-1.2 3. 在 HotSport 虚拟机中，对象的内存布局主要包括 1）对象头（Header） 包含两部分信息： **Mark Word：**用于存储对象的 hashCode、锁状态标志、线程持有锁的 ID、GC 分代年龄等信息。 **类型指针：**指向对象的类定义的指针，即指向元数据的方法表（Method Table），它用于动态方法分派。 2）实例数据（Instance Data） 存储实际的类字段信息，包括父类的字段和子类中定义的字段。这部分的存储顺序受字段在 Java 源码中定义的顺序影响，但可能经过 JVM 的优化调整。 3）填充数据（Padding） 对齐填充，HotSpot JVM 要求对象的起始地址必须是 8 字节的倍数。填充数据用于确保对象的内存地址满足对齐要求。 4）数组长度（对于数组对象） 如果对象是数组类型，那么对象头中还包含一个数组长度的字段，用于存储数组的长度。 5）对齐要求 HotSpot JVM 要求对象的大小必须是 8 字节的整数倍，这是为了满足对象访问的效率和内存对齐的要求。 4. ReentrantLock 原理，以及和 synchronized 的区别 相比于 synchronized，ReentrantLock 需要显式的获取锁和释放锁，相对现在基本都是用 JDK7 和 JDK8 的版本，ReentrantLock 的效率和 synchronized 区别基本可以持平了。他们的主要区别有以下几点： 等待可中断，当持有锁的线程长时间不释放锁的时候，等待中的线程可以选择放弃等待，转而处理其他的任务。 公平锁：synchronized 和 ReentrantLock 默认都是非公平锁，但是 ReentrantLock 可以通过构造函数传参改变。只不过使用公平锁的话会导致性能急剧下降。 绑定多个条件：ReentrantLock 可以同时绑定多个 Condition 条件对象。 ReentratLock 基于 AQS（Abstract Queued Synchronizer 抽象队列同步器）实现，AQS 的原理如下： AQS 内部维护一个 state 状态位，尝试加锁的时候通过 CAS（Compar","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:2:5","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"一、数据库 ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:3:0","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"1. MySQL高频面试题 1.1 索引相关 1. 什么是索引 索引是一种数据结构，类似于书籍目录，可以帮助数据库快速定位和访问表中特定数据行。 2. 索引是个什么样的数据结构呢? 索引的数据结构和具体存储引擎的实现有关，在 MySQL 中使用较多的索引有 Hash 索引，B+ 树索引 等，而MySQL默认的 InnoDB 存储引擎的索引实现默认为：B+ 树索引。 3. Hash 索引和 B+ 树索引有什么区别以及优劣势? 首先要知道 Hash 索引和 B+ 树索引的底层实现原理： Hash 索引底层就是 Hash 表，进行查找时，调用一次 Hash 函数就可以获取到相应的键值，后进行回表查询获得实际数据。 B+ 树底层实现是多路平衡查找树。对于每一次的查询都是从根节点出发，查找到叶子节点方可以获得所查键值，然后根据查询判断是否需要回表查询数据。 二者的不同之处： 因为在 Hash 索引中经过 Hash 函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。而 B+ 树的所有节点皆遵循左节点 \u003c 父节点 \u003c 右节点，天然支持范围查询。 Hash 索引不支持使用索引进行排序，原理同上。 Hash 索引不支持模糊查询以及多列索引的最左前缀匹配。原理也是因为hash函数的不可预测。 Hash 索引任何时候都避免不了回表查询数据，而 B+ 树在符合某些条件（聚簇索引，覆盖索引等）的时候可以只通过索引完成查询。 Hash 索引虽然在等值查询上较快，但是不稳定，性能不可预测，当某个键值存在大量重复的时候,发生 Hash 碰撞，此时效率可能极差。而 B+ 树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低。 4. 什么是聚簇索引、覆盖索引? 聚簇索引： **定义：**聚簇索引是一种数据存储方式，表中的数据行按索引的顺序实际存储在磁盘上。一个表只能有一个聚簇索引，因为数据行只能按一种顺序排列。 特性： 数据存储顺序：数据行的物理顺序与索引顺序一致。 高效查询：对索引键值的范围查询、排序查询性能较高，因为数据按索引顺序存储，减少了数据访问的随机性。 主键作为聚簇索引：通常情况下，主键会被设置为聚簇索引。如果没有主键，则挑选一个唯一键建立聚簇索引。如果没有唯一键，则隐式的生成一个键来建立聚簇索引。 更新和插入：插入和删除操作可能会导致数据的重新排列，从而影响性能。 索引包含数据：叶节点包含实际数据行，不需要二次查询。 **示例：**假设有一个表 students，包含 student_id（主键）和 name 列。如果 student_id 是聚簇索引，那么数据行会按 student_id 排序存储。 覆盖索引： **定义：**覆盖索引是指一个索引包含所有查询所需的字段，查询可以只通过索引获得所有需要的数据，而不需要访问数据行。 特性： 减少I/O操作：因为索引包含了所有查询需要的字段，查询可以完全从索引中获取数据，不需要再访问数据行，减少了I/O操作。 提高查询性能：在只需访问索引的情况下，查询性能大幅提高，特别是对于大表和复杂查询。 多列索引：通常通过多列联合索引实现，确保索引覆盖查询中的所有列。 **示例：**假设有一个表 students，包含 student_id、name 和 age 列。若有一个查询 SELECT student_id, name FROM students WHERE age = 20，并且有一个联合索引 INDEX (age, student_id, name)，则这个索引就是覆盖索引，因为它包含了查询所需的所有字段。 5. 联合索引是什么?为什么需要注意联合索引中的顺序? MySQL可以使用多个字段建立联合索引。要命中联合索引，查询时必须按字段建立时的顺序使用这些字段。 原因是 MySQL 需要有序索引。例如，若有 name, age, school 的联合索引，索引先按 name 排序，name 相同时再按 age 排序，最后按 school 排序。因此，建立联合索引时，应将查询频繁或选择性高的列放在前面，也可以根据具体查询需求和表结构进行调整。 6. 创建的索引有没有被使用到?或者说怎么才可以知道这条语句运行很慢的原因? MySQL提供了 EXPLAIN 命令来查看查询语句的执行计划。MySQL在执行语句前，会通过查询优化器分析该语句，生成执行计划，其中包含许多重要信息。通过这些信息，可以判断是否命中了索引。例如，possible_keys、key 和 key_len 字段分别表示可能使用的索引、实际使用的索引以及索引用的长度。 1.2 事务相关 1. 什么是事务? 数据库的事务（Transaction）是一组逻辑操作单元，这些操作要么全部执行成功，要么全部回滚。 假设有一个银行转账的场景，从账户 A 转账 100 元到账户 B，这个操作可以分为以下几步： 检查账户A的余额是否足够。 从账户A扣除100元。 向账户B增加100元。 这几步操作必须作为一个事务处理，要么全部执行成功，要么全部失败回滚。如果在扣除账户A的100元后，系统发生故障，事务应该回滚，恢复账户A的100元。 2. 同时有多个事务在进行会怎么样呢? 脏读：事务 A 读取到事务 B 未提交的数据，而事务 B 随后回滚了这些数据。 不可重复读：事务 A 在同一事务内的两次查询结果可能会不同，因为在此期间事务 B 进行了提交操作。 幻读：事务 A 读取了一个范围内的数据，同时事务 B 在此范围内插入了一条新数据，导致事务A产生“幻觉”，即在后续查询中看到额外的数据。 3. 不可重复读和幻读的区别： 不可重复读：关注的是同一行数据在两次读取之间被修改。重点在于修改操作。 幻读：关注的是查询结果集在两次读取之间因插入或删除数据而发生变化。重点在于插入或删除操作。 **4. MySQL的事务隔离级别了解吗? ** 未提交读 (READ UNCOMMITTED)：在这个隔离级别下，其他事务可以看到本事务未提交的修改，因此会出现脏读的问题（读取到其他事务未提交的数据，而这些数据可能会被回滚）。由于性能优势不明显且存在较多问题，这个级别很少使用。 已提交读 (READ COMMITTED)：其他事务只能读取到本事务已经提交的数据。在这个隔离级别下，会出现不可重复读的问题，即同一事务内的两次读取结果可能不同，因为另一事务在中间修改了数据。 可重复读 (REPEATABLE READ)：可重复读隔离级别解决了不可重复读的问题，但仍然可能出现幻读。当读取 id \u003e 10 的数据行时，会对所有涉及的行加上读锁。但如果另一个事务在此期间插入了一条id=11的数据，由于新插入的数据不受之前锁的影响，下一次查询会发现多了一条id=11的数据，而上次查询没有获取到。这可能导致主键冲突的问题。 可串行化 (SERIALIZABLE)：这是最高的隔离级别，可以解决所有问题，因为它强制将所有操作串行执行。然而，这会导致并发性能显著下降，因此也很少使用。 5. InnoDB 使用的是哪种隔离级别呢? InnoDB 默认使用的是可重复读隔离级别。 6. 对 MySQL 的锁了解吗? 锁的类型 全局锁：锁住整个数据库实例，通常用于备份和恢复操作。执行 FLUSH TABLES WITH READ LOCK 命令会加上全局锁。 表级锁：锁住整个表，分为读锁和写锁。 读锁（共享锁）：多个事务可以同时读，但不能写。 写锁（排他锁）：其他事务既不能读也不能写。 锁的存储引擎 InnoDB存储引擎： 默认使用行级锁。 支持自动死锁检测和自动回滚。 支持外键和事务。 MyISAM存储引擎： 只支持表级锁。 适用于读多写少的应用场景。 死锁：当两个或多个事务互相等待对方持有的锁时，便会产生死锁。InnoDB 引擎能够自动检测并处理死锁，通过回滚其中一个事务来解决。 7. 事务的分类 事务事务可以分为很多中类型，一般分为：扁平事务、带有保存点的扁平事务、链事务、嵌套事务、分布式事务。 扁平事务 扁平事务是事务管理中的基础形式，广泛应用于实际开发。它以单一层次执行所有操作，其主要缺点是不能提交或回滚事务的某一部分，或者分几个独立的步骤去提交。 /* BEGIN WORK Operation 1 Operation 2 Operation 3 ... Operation N COMMIT WORK */ # 举例 BEGIN WORK; SELECT * FROM tale_name; UPDATE table_name SET field1 = \"xxx\" WHERE field2 = 1; COMMIT WORK; 带有保存点的扁平事务 带有保存点的扁平事务，不仅包含扁平事务的功能，还增加了回滚至事务早期状态的能力。当事务执行中出现错误，并非所有操作都需废弃，完全回滚可能代价过高。为此，引入了保存点机制，它允许系统记录事务的特定状态，以便在出错时能够回退到该点，从而优化资源利用并减少不必要的开销。 BEGIN WORK; SELECT * FROM tale_name; SAVEPOINT t1; # 建立保存点 t1 UPDATE table_name SET field1 = \"xxx\" WHERE field2 = 1; SAVEPOINT t2; # 建立保存点 t2 COMMIT WORK; # 通过 ROLLBACK TO SAPOINT t1, 就可以返回保存点 t1 链事务 链事务是一种高效的事务处理方式，它在提交当前事务时，自动释放非必需的数据对象，并将必要的处理上","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:3:1","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"2. MySQL 优化方案 在开始介绍如何优化 SQL 之前，先附上 MySQL 内部逻辑图。 img-1.1 **① 连接器：**主要负责跟客户端建立连接、获取权限、维持和管理连接 **② 查询缓存：**优先从缓存中查询数据，若缓存中有结果则直接返回；否则，再从数据库查询。 MySQL 缓存是默认关闭的，在 MySQL 8.0 中已移除该功能，主要因为其使用场景受限： 缓存的存储格式为键值对（key: SQL 语句，value: 数据值），SQL 语句若有任何不同都会导致直接数据库查询； 由于数据经常变化，相关缓存数据需在数据库更新时移除。 ③ 解析器/分析器：负责对 SQL 语句进行词法和语法解析，生成抽象语法树，并使用预处理器进行语义校验，确保表和字段存在。 **④ 优化器：**将经过词法和语法解析后的语法树，通过数据字典和统计信息，经过运算得出执行计划，包括选择使用哪个索引 **⑤ 执行器：**根据执行计划，调用存储引擎提供的 API 接口，完成 SQL 的执行。 SQL 语句及索引的优化 1. 避免使用子查询 # 低效 SELECT * FROM t1 WHERE id IN (SELECT id FROM t2 WHERE name = 'tang'); # 优化 SELECT t1.* FROM t1 JOIN t2 ON t1.id = t2.id; 由于MySQL优化器对子查询处理能力较弱，建议改写成 Inner Join，这样 MySQL 不需在内存中创建临时表，效率更高。但需注意：这种优化仅对 SELECT 有效，对 UPDATE/DELETE 中的子查询无效，因此在生产环境中应尽量避免使用子查询。 2. 用 IN 替换 OR # 低效 SELECT * FROM t WHERE id = 10 OR id = 20 OR id = 30; # 高效 SELECT * FROM t WHERE id IN (10, 20, 30); MySQL 对 IN 进行了优化，将 IN 中的常量存储在一个已排序的数组中。但如果数值较多，消耗也会增大。例如，对于连续数值，使用 BETWEEN 代替 IN；或使用连接替换。 3. 读取适当记录 LIMIT M,N # 低效 SELECT id, name FROM t LIMIT 866613, 20; # 优化 SELECT id, name FORM table_name WHERE id \u003e 866613 LIMIT 20; 随着表数据量增加，LIMIT 分页查询会变慢。MySQL 并非跳过 OFFSET 行，而是取 OFFSET+N行，放弃前 OFFSET 行，返回 N 行。OFFSET 越大，效率越低。可以采取——先取前一页最大行的 ID，然后通过该 ID 限制下一页起点。 4. 禁止不必要的 Order By 排序 # 低效 SELECT goods_id, count(*) FROM t GROUP BY goods_id; # 高效 SELECT goods_id, count(*) FROM t GROUP BY goods_id ORDER BY NULL; 如果对结果没有排序要求，尽量少用排序；如果排序字段未使用索引，也应少用排序；分组统计查询时可以禁止默认排序。 5. 总和查询可使用UNION ALL UNION 需要合并结果集并进行唯一性过滤，增加 CPU 运算和资源消耗。而 UNION ALL 则不进行唯一性过滤，适用于没有重复数据的情况，提高速度。 6. 避免随机取记录 SELECT * FROM t1 WHERE 1 = 1 ORDER BY RAND() LIMIT 4; SELECT * FROM t1 WHERE id \u003e= CEIL(RAND() * 1000) LIMIT 4; 以上语句无法使用索引。 7. 将多次插入改为批量Insert # 低效 INSERT INTO t(id, name) VALUES (1, 'aaa'); INSERT INTO t(id, name) VALUES (2, 'bbb'); INSERT INTO t(id, name) VALUES (3, 'ccc'); # 高效 INSERT INTO t(id, name) VALUES (1, 'aaa'), (2, 'bbb'), (3, 'ccc'); **8. 只返回必要列，避免使用 SELECT * ** 使用具体字段列表代替SELECT *，以减少不必要的消耗，增加使用覆盖索引的可能性，并减少表结构变化带来的影响。 9. 区分 IN 和 EXISTS IN（先执行子查询）适合外表大而内表小的情况；EXISTS （先访问外层表）适合外表小而内表大的情况。IN 可能返回错误结果，建议在确定且有限的集合时使用。 10. 优化 Group By 语句 # 低效 SELECT job, AVG(sal) FROM emp GROUP BY job HAVING job = 'PRESIDENT' OR job = 'MANAGER' # 高效 SELECT job, AVG(sal) FROM emp WHERE job = 'PRESIDENT' OR job = 'MANAGER' GROUP BY job; 如果对 Group By 结果没有排序要求，使用ORDER BY NULL； 尽量让 Group By 过程使用表的索引； 通过调大 tmp_table_size 参数，避免使用磁盘临时表； 使用 SQL_BIG_RESULT 提示优化器直接使用排序算法； 避免使用HAVING子句，改用WHERE子句提前过滤数据。 11. 尽量使用数字型字段 数值型字段的查询和连接性能优于字符型字段，避免逐个字符比较。 12. 优化Join语句 执行 Join 时，两个表的数据逐条比较会很慢。可以调整 Join Buffer 大小，提高性能。 在连接查询没有 WHERE 条件时，左连接的左表为驱动表，右连接的右表为驱动表，INNER JOIN 自动选择数据少的表为驱动表。存在WHERE条件时，带条件的表为驱动表。 驱动表和被驱动表的数据量、索引、Join Buffer Size 等都会影响 Join 语句的性能。尽量减少 Join 语句中的Nested Loop 次数，用小结果集驱动大结果集，优先优化 Nested Loop 的内层循环，对被驱动表的 Join 字段建立索引，避免左连接时的性能问题，适当添加冗余信息。 13. 索引优化 遵守最佳左前缀法则，不在索引列上进行计算或函数操作，避免索引失效。 MySQL 8.0 开始支持函数索引。 避免类型转换导致索引失效，存储引擎不能使用索引中范围条件右边的列。 尽量使用覆盖索引，减少 select *，负向查询条件和 NULL 判断可能导致索引失效。 LIKE 通配符使用时避免以 % 开头。 尽量减少 OR 条件，确保索引有效，区分度高的索引放在前面。 使用前缀索引减少索引长度。EXPLAIN 中的 type 至少要达到 range 级别，最好是 consts。 ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:3:2","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"3. MySQL的又一神器-锁 3.1 什么是锁 1. 锁的概述 在 MySQL 中，锁是一个重要的特性。数据库使用锁来支持并发访问共享资源，确保数据的完整性和一致性，从而在高并发情况下保证数据的正确性。 2. 锁的两个概念 在数据库中，锁（lock）和闩锁（latch）都有锁的含义，但它们的用途和特性不同。 Latch（闩锁）：是一种轻量级锁，要求锁定时间非常短。如果锁定时间过长，会显著影响应用性能。在InnoDB 引擎中，Latch 分为互斥量（mutex）和读写锁（rwlock），用于确保并发线程操作临界资源的正确性，通常没有死锁检测机制。 Lock（锁）：与事务相关，用于锁定数据库对象（如表、页、行）。Lock 通常在事务提交（commit）或回滚（rollback）后释放，不同事务隔离级别可能影响释放时间。 3.2 InnoDB 存储引擎中的锁 1. 锁的粒度 在数据库中，锁的粒度可以分为表锁、页锁和行锁。这些锁的粒度可以升级，例如将多个行锁升级为一个页锁，或将页锁升级为表锁。 表锁：表锁是 MySQL 存储引擎中粒度最大的锁，逻辑简单，系统负面影响小，获取和释放速度快，避免了死锁问题。然而，锁定整个表会导致资源争用，降低并发度。表锁主要用于 MyISAM、MEMORY、CSV 等非事务性存储引擎。 特点：开销小、加锁快、不出现死锁、锁定粒度大、锁冲突概率高、并发度低。 页锁：页锁是 MySQL 中的一种独特锁定级别，锁定粒度介于表锁和行锁之间，资源开销和并发能力也介于两者之间。页锁和行锁一样会发生死锁，主要用于 BerkeleyDB 存储引擎。 特点：开销和加锁时间介于表锁和行锁之间、会出现死锁、锁定粒度适中、并发度一般。 行锁：行锁锁定对象粒度最小，资源争用概率最低，提供最大的并发处理能力，但开销大、加锁慢，最容易发生死锁。 开销大、加锁慢、会出现死锁、锁定粒度最小、锁冲突概率最低、并发度最高。 2. 锁的类型 数据操作主要有两种：读和写。数据库对这两种操作使用不同的锁；InnoDB 实现了标准的行级锁，即共享锁（Shared Lock, S Lock）和排他锁（Exclusive Lock, X Lock）。 共享锁（读锁，S Lock）：允许事务读取一行数据。 排他锁（写锁，X Lock）：允许事务删除或更新一行数据。 为了允许行锁和表锁共存，InnoDB 支持一种额外的锁机制——意向锁。意向锁是表级锁，用于实现多粒度锁机制，分为以下两种： 意向共享锁（IS Lock）：表示事务想要获取一张表中某几行的共享锁。 意向排他锁（IX Lock）：表示事务想要获取一张表中某几行的排他锁。 这些锁之间并非总是兼容的。有些锁之间存在冲突。例如，事务A获取某行某种锁后，事务B尝试获取同一行上的某种锁。如果B能够立即获取锁，则称为锁兼容；否则称为冲突。 锁类型的兼容性 IS 锁 IX 锁 S 锁 X 锁 IS 锁 ✔ ✔ ✔ ✖ IX 锁 ✔ ✔ ✖ ✖ S 锁 ✔ ✖ ✔ ✖ X 锁 ✖ ✖ ✖ ✖ 4. 一致性锁定读和一致性非锁定读 一致性锁定读 (Locking Reads) 在事务中执行查询时，普通的 SELECT 语句不会对数据加锁，其他事务仍可以更新和删除这些数据。为提供更高的安全性，InnoDB 提供了两种锁定读： SELECT ... LOCK IN SHARE MODE：对读取的行加 S 锁，其他事务可以对这些行加 S 锁，但加 X 锁会被阻塞。 SELECT ... FOR UPDATE：对查询的行及相关索引记录加 X 锁，其他事务的 S 锁或 X 锁请求都会被阻塞。这些锁在事务提交或回滚后释放。注意，只有在禁用自动提交时，SELECT FOR UPDATE 才能锁定行；若开启自动提交，匹配的行不会被锁定。 一致性非锁定读 (Consistent Nonlocking Read) 一致性非锁定读是指 InnoDB 存储引擎通过多版本控制（MVCC）读取行数据。如果行正在执行 DELETE 或 UPDATE 操作，读取操作不会等待行锁的释放，而是读取行的一个快照。这种机制显著提高了数据库的并发性。 一致性非锁定读是InnoDB的默认读取方式，即读取操作不会占用和等待行上的锁。在事务隔离级别 READ COMMITTED 和 REPEATABLE READ 下，InnoDB 使用一致性非锁定读。 READ COMMITTED 隔离级别：读取最新的快照数据。 REPEATABLE READ 隔离级别：读取事务开始时的行数据版本。 5. 行锁的算法 InnoDB存储引擎有3种行锁的算法，其分别是： Record Lock：单个行记录上的锁。 Gap Lock：间隙锁，锁定一个范围，但不包含记录本身。 Next-Key Lock：锁定一个范围，并且锁定记录本身。 Record Lock：总是会去锁住索引记录，如果 InnoDB 存储引擎表在建立的时候没有设置任何一个索引，那么这时 InnoDB 存储引擎会使用隐式的主键来进行锁定。 Gap Lock的作用：是为了阻止多个事务将记录插入到同一个范围内，设计它的目的是用来解决 Phontom Problem（幻读问题）。在 MySQL 默认的隔离级别（Repeatable Read）下，InnoDB 就是使用它来解决幻读问题。 Next-Key Lock：结合了 Gap Lock 和 Record Lock 的一种锁定算法，在 Next-Key Lock 算法下，InnoDB 对于行的查询都是采用这种锁定算法。除了Next-Key Locking，还有 Previous-Key Locking 技术，这种技术跟 Next-Key Lock 正好相反，锁定的区间是区间范围和前一个值。举个例子10，20，30，那么这两种索引的锁定区间为： img-1.2 3.3 锁带来的问题 脏读 不可重复读 幻读 READ UNCOMMITTED ✔ ✔ ✔ READ COMMITTED ✖ ✔ ✔ REPEATABEL READ ✖ ✖ ✖ SERIALIZABLE ✖ ✖ ✖ ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:3:3","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"二、系统设计 ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:4:0","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"1. 前后端分离概述 1.1 前后端分离和 SPA 前后端分离的典型例子是单页应用（SPA，Single-page Application），它通过异步接口（AJAX/JSONP）从后端获取数据，前端只负责展示。然而，这种方法存在两个问题： 应用范围受限：在 Web 服务中，SPA 所占比例较少。很多场景下，需要同步或同步 + 异步的混合模式，SPA 无法作为通用解决方案。 职责不清：现阶段的 SPA 开发中，接口通常按照展现逻辑提供，同时为了提高效率，后端也参与了视图层的工作，这不是真正的前后端分离。 为了真正实现前后端分离，应从职责上进行划分： 前端：负责 View 和 Controller 层。 后端：只负责 Model 层，处理业务和数据持久化。 1.2 Node.js 的作用 **1. Node.js 的研发背景：**在前后端完全分离的时代，前端的职责扩展到 Controller 层。然而，前后端在职责和技术上的差异可能导致以下问题： 技术隔阂：后端开发人员不熟悉前端 HTML 结构，前端开发人员不了解后端代码。 开发效率：前端需要快速上手，而 Node.js 的出现解决了这些问题。Node.js 适合高并发、I/O 密集、少量业务逻辑的场景，前端开发人员可以快速掌握。 2. Node.js 的工作流程 浏览器请求 Node.js 服务器。 Node.js 服务器请求后端 JSP 接口。 JSP 接口返回 JSON 数据给 Node.js。 Node.js 将 JSON 数据渲染为 HTML 页面。 Node.js 将 HTML 页面发送给浏览器。 3. Node.js 作为中间层的好处 **适配性提升：**Node.js 中间层可以为 PC 端、移动端和 APP 端提供统一的接口，简化前端与后端的交互，减少沟通成本。 响应速度提升：Node.js 可以在中间层处理部分逻辑，减轻前端和后端的负担，提高响应速度。 性能提升：Node.js 中间层可以将多个后端接口的数据在内网阶段拼装好，减少前端请求次数，提高性能。 异步与模板统一：Node.js 支持异步操作，前端模板可以在不同条件下使用不同渲染方式，提高页面渲染效率。 ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:4:1","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"2. 前后端分离之 JWT 用户认证 在前后端分离开发中，用户认证至关重要。由于 HTTP 协议是无状态的，每次请求时，服务器无法记住先前的认证状态。为了确保系统安全，必须在每次请求中验证用户的登录状态。 1. 传统方式 在传统的前后端分离模式中，通过 Restful API 进行数据交互，通常采用以下方式进行用户认证： 前端登录：用户通过前端输入账号和密码进行登录。 生成Token：后端根据用户信息生成一个 Token，并将其与用户 ID 一起存储在数据库或 Session 中。 传递Token：后端将生成的 Token 传递给前端，前端将 Token 存储在浏览器的 Cookie 中。 请求验证：浏览器在每次请求时携带 Cookie，后端根据 Cookie 中的 Token 查询用户，验证其登录状态。 这种方法存在诸多问题，例如 XSS漏洞 可能导致 Token 泄露。虽然可以通过设置 httpOnly 和 secure 属性来保护 Cookie，但这并不能完全防止跨站请求伪造（XSRF）攻击。此外，存储在数据库中的验证信息每次都需要查询，增加了服务器的开销。 2. Json Web Token（JWT） JWT 是一种开放标准（RFC 7519），用于在通信双方之间以 JSON 对象的形式安全传递信息。JWT 具有简洁（Compact）和自包含（Self-contained）的特点： 简洁：可以通过 URL、POST 参数或 HTTP 头部传递，数据量小，传输速度快。 自包含：负载中包含了所有需要的信息，避免了多次查询数据库。 3. JWT 的使用 用户登录：前端通过 Web 表单将用户名和密码发送到后端（建议使用 HTTPS）。 生成 JWT：后端验证成功后，生成包含用户信息的 JWT，并将其返回给前端。 存储 JWT：前端将 JWT 存储在 localStorage 或 sessionStorage 中。 请求时携带 JWT：前端在每次请求时将 JWT 放入 HTTP 头部的 Authorization 字段中。 验证 JWT：后端检查 JWT 的有效性，包括签名是否正确、Token 是否过期等。 处理请求：验证通过后，后端使用 JWT 中的信息进行处理，并返回结果。 4. 比较和总结 相比传统的 Session 方式，JWT 将用户状态分散到客户端，减轻了服务器的存储压力。虽然 JWT 会增加服务器的计算压力，但在很多场景下，这种压力是可以接受的。JWT 特别适用于需要传递非敏感信息的场景，如用户 ID 等。 对于大型应用，使用 JWT 可以避免 Session 同步的复杂性，特别是在多服务器和多子域名的情况下。JWT 还可以用于实现单点登录（SSO）。 最后，JWT 不应包含敏感信息，如用户密码，应仅用于传递非敏感信息，以确保安全性。 Session JWT 存储状态 Session 会话信息存储在服务器 JWT 令牌存储在客户端 扩展性 Seesion 需要服务器在内存或数据库中保存会话信息，当用户数量增多时，需要更多的存储资源。 JWT 令牌包含了用户信息和声明，服务器可以避免频繁访问存储，使得系统更容易扩展。 状态性 Session 依赖服务器的状态来验证用户身份，需要在服务器端保存会话状态。 JWT 是无状态的，服务器可以直接解密和验证令牌，无需保存任何状态信息。 跨域通信 Session 则需要处理跨域通信的问题 JWT 存储在客户端，可以轻松地在不同域名的服务器之间传递 时效性 Session 的有效期由服务器控制，可以设置较短的时间以提高安全性，但可能导致用户需要频繁重新登录。 JWT 可以包含令牌的过期时间，客户端可据此判断是否需要刷新令牌。 ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:4:2","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"3. 单点登录机制原理 3.1 单系统登录机制 1. http 无状态协议 Web 应用采用 browser/server 架构，http 作为通信协议。http 是无状态协议，浏览器的每一次请求，服务器会独立处理，不与之前或之后的请求产生关联，访问服务器资源虽然方便，但也带来了安全风险。为了保护敏感数据，我们需要对浏览器的访问请求进行限制。这就需要服务器识别并响应合法请求，同时忽略非法请求。由于HTTP协议本身是无状态的，因此需要服务器和浏览器共同维护一个会话状态，这就是会话机制的作用。 2. 会话机制 浏览器首次向服务器发起请求时，服务器会创建一个会话，并生成一个唯一的会话 ID。这个 ID 随后作为响应的一部分发送回浏览器。浏览器接收到 ID 后，将其存储起来。在随后的请求中，浏览器会在请求头中携带这个会话 ID。服务器通过检查请求中的会话 ID，就能识别出请求是否来自同一个用户，从而建立起请求之间的关联。 3. 登录状态 通过会话机制，我们可以清晰地管理用户的登录状态。设想浏览器首次向服务器发起请求时，需要提供用户名和密码以验证身份。服务器接收到这些凭据后，会与数据库中的记录进行比对。如果验证成功，服务器便确认当前会话的用户是合法的，并应该将该会话标记为“已授权”或“已登录”。这种状态信息自然需要存储在会话对象中。Tomcat 服务器在会话对象中设置登录状态的方式如下： HttpSession session = request.getSession(); // 在会话对象中添加标识，表示用户是否已经通过身份验证 session.setAttribute(\"isLogin\", true); // 服务器在用户进行后续请求时，通过会话对象快速识别其登录状态，从而提供相应的服务和权限 HttpSession session = request.getSession(); session.getAttribute(\"isLogin\"); 3.2 多系统的复杂性 随着 Web 系统的发展，我们从单一的系统演变为由多个子系统组成的复杂应用群。用户在使用这些系统时，不应该面临重复登录和注销的繁琐过程。系统的复杂性应该由系统内部处理，而不是转嫁给用户。用户应该能够像访问单一系统一样，仅需一次登录和注销，就能便捷地使用整个Web应用群。 单系统登录解决方案虽然在单一系统中运行良好，但在多系统组成的应用群中却显得力不从心。原因如下： Cookie 的域限制：Cookie 的有效范围受限于其设置的域。浏览器只会发送与请求域名匹配的 Cookie，这意味着不同域的系统无法通过 Cookie 共享会话状态。 域名统一的挑战：即使将所有子系统放在一个顶级域名下，如 “*.baidu.com”，并将 Cookie 的域设置为 “baidu.com”，这种做法在理论上可行，但在实践中存在诸多限制。应用群的域名需要统一管理，这在大型组织或使用不同子域的系统中可能难以实现。 技术栈的多样性：不同子系统可能使用不同的技术栈，例如 Java、PHP、.NET 等。这些系统可能使用不同的会话管理机制和 Cookie key 值，导致共享 Cookie 的方式无法跨技术平台工作。 安全性问题：Cookie存储在用户浏览器上，容易受到跨站脚本（XSS）和跨站请求伪造（CSRF）等攻击，存在安全隐患。 鉴于这些限制，单点登录（SSO）成为了解决多系统应用群登录问题的理想方案。SSO允许用户只需登录一次，即可访问所有相关联的系统，而无需重复认证。 3.3 单点登录 单点登录（Single Sign-On，简称SSO）是一种身份验证机制，它允许用户在多个系统组成的应用群中，只需登录一次即可访问所有系统，而无需重复登录。SSO 包括单点登录和单点注销两个主要部分。 1. 登录 当用户首次登录时，认证中心会验证其凭据。一旦验证通过，认证中心将创建一个授权令牌并发送给用户。这个令牌随后作为参数在用户访问其他子系统时传递。子系统接收到令牌后，会与认证中心通信以验证令牌的有效性。验证成功后，子系统便可以基于这个令牌为用户创建局部会话，允许用户访问系统资源，而这个过程对用户来说是透明的。 img-2.1 对上图的简要阐述： 步骤 描述 1. ~ 3. 用户访问系统 1 的受保护资源，系统 1 发现用户未登录，跳转至 SSO 认证中心，并将自己的地址作为参数； 4. 5. SSO 认证中心发现用户未登录，将用户引导至登录页面； 6. 用户输入用户名密码提交登录申请； 7. ~ 9. SSO 认证中心校验用户信息，创建用户与 SSO 认证中心之间的会话，称为全局会话，同时创建授权令牌； 10. SSO 认证中心带着令牌跳转会最初的请求地址（系统1）； 11. 系统 1 拿到令牌，去 SSO 认证中心校验令牌是否有效； 12. ~ 14. SSO 认证中心校验令牌，返回有效，注册系统 1； 15. 16. 系统 1 使用该令牌创建与用户的会话，称为局部会话，返回受保护资源； 17. 用户访问系统 2 的受保护资源； 18. 19. 系统 2 发现用户未登录，跳转至 SSO 认证中心，并将自己的地址作为参数； 20. 21. 认证中心发现用户已登录，跳转回系统 2 的地址，并附上令牌； 22. 系统2拿到令牌，去 SSO 认证中心校验令牌是否有效； 23. ~ 25. SSO 认证中心校验令牌，返回有效，注册系统 2； 26. 27. 系统 2 使用该令牌创建与用户的局部会话，返回受保护资源。 用户登录成功之后，会与sso认证中心及各个子系统建立会话 用户与sso认证中心建立的会话称为全局会话 用户与各个子系统建立的会话称为局部会话，局部会话建立之后，用户访问子系统受保护资源将不再通过 SSO 认证中心 全局会话与局部会话有如下约束关系： 局部会话存在，全局会话一定存在； 全局会话存在，局部会话不一定存在； 全局会话销毁，局部会话必须销毁。 2. 注销 单点登录自然也要单点注销，在一个子系统中注销，所有子系统的会话都将被销毁，用下面的图来说明 img-2.2 SSO 认证中心一直监听全局会话的状态，一旦全局会话销毁，监听器将通知所有注册系统执行注销操作。 下面对上图简要说明： 步骤 描述 1. 用户向系统 1 发起注销请求； 2. 3. 系统 1 根据用户与系统 1 建立的会话 id 拿到令牌，向 SSO 认证中心发起注销请求； 4. ~ 6. SSO 认证中心校验令牌有效，销毁全局会话，同时取出所有用此令牌注册的系统地址； 7. ~ 9. SSO 认证中心向所有注册系统发起注销请求，各注册系统接收 SSO 认证中心的注销请求，销毁局部会话； 10. SSO 认证中心引导用户至登录页面。 3.4 部署图 单点登录是一个涉及 SSO 认证中心和多个子系统的复杂流程。在这个流程中，子系统必须集成 SSO 客户端，以便与作为服务端的 SSO 认证中心进行通信，交换令牌、验证令牌有效性，并处理注销请求。整个过程实质上是客户端与服务端之间的通信，用下图描述（）： img-2.3 SSO 认证中心与 SSO 客户端通信方式有多种包括： httpClient Web Service RPC Restful API 3.5 实现 SSO 采用客户端/服务端架构，具体可以先看 SSO Client 与 SSO Server 要实现的功能 SSO Client： 拦截子系统未登录用户请求，跳转至 SSO 认证中心； 接收并存储 SSO 认证中心发送的令牌； 与 SSO Server 通信，校验令牌的有效性； 建立局部会话； 拦截用户注销请求，向 SSO 认证中心发送注销请求； 接收 SSO 认证中心发出的注销请求，销毁局部会话。 SSO Server 验证用户的登录信息； 创建全局会话； 创建授权令牌； 与 SSO Client 通信发送令牌； 校验 SSO Client 令牌有效性； 系统注册； 接收 SSO Client 注销请求，注销所有会话。 ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:4:3","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"4. 微服务 4.1 微服务的好处 1. 单体项目的缺点 **可扩展性受限：**单体应用通常在可扩展性方面受到限制。因为整个应用程序必须一起扩展。这意味着即使只有一个组件需要更多资源，也必须扩展整个应用程序，这可能会导致资源浪费。 **难以维护和更新：**随着时间的推移，单体应用程序往往变得越来越庞大和复杂，难以理解、维护和更新。每次修改都可能引发一项不到的影响。 **高风险：**单体应用程序中的一个小错误或故障可能会导致整个应用程序崩溃，因此存在较高的风险。此外，长时间不更新的单体应用可能会收到安全威胁。 **技术栈限制：**单体应用程序通常使用相同的技术栈，这可能会限制在项目中使用最新的技术和工具的能力。 **团队协作复杂：**单体应用程序的所有组件都在同一个代码库中，这可能导致开发团队之间的冲突和协作问题，尤其是在大型团队中更为突出 2. 微服务项目的优点： **高度可扩展性：**微服务架构通过将应用程序拆分成多个小型的服务，每个服务都可以独立地进行扩展。服务的自治性允许我们根据需求对每个服务进行独立的水平扩展，而不必对整个应用程序进行扩展。这种高度扩展性适合应对大规模、高并发的应用场景。 **独立开发和部署：**微服务架构将一个大型应用程序拆分成多个小型服务，每个服务都有自己的代码库和开发团队。这种独立性使得不同团队可以并行开发和部署各自的服务，提高了开发效率和灵活性。 ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:4:4","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"三、分布式 ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:5:0","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"1. Dubbo 1. Dubbo 是什么？ Dubbo是阿里巴巴开源的基于 Java 的，高性能远程服务调用（RPC，Remote Procedure Call） 分布式服务框架，现已成为 Apache 基金会孵化项目。其核心部分内容包含： **集群容错：**提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。 远程通讯： 提供对多种基于长连接的 NIO 框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。 **自动发现：**基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。 2. Dubbo 能做什么？ 透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API 侵入。 软负载均衡及容错机制，可在内网替代 F5 等硬件负载均衡器，降低成本，减少单点。 服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的 IP 地址，并且能够平滑添加或删除服务提供者。 3. 默认使用什么通信框架？ 默认（推荐）使用 Netty 框架，除了 Netty，还有 Mina、Grizzly。 4. 服务调用是阻塞的吗？ 默认是阻塞的，但支持异步调用。 Dubbo 是基于 NIO 的非阻塞实现并行调用，客户端不需要启动多线程即可完成并行调用多个远程服务，相对多线程开销较小，异步调用会返回一个 Future 对象。 异步调用流程图如下： img-3.1 5. Dubbo 和 Spring Cloud 有什么区别？ 1）通信方式不同 Dubbo 使用的是 RPC 通信，而 Spring Cloud 使用的是 HTTP RESTFul 方式。 2）组成部分不同 组件 Dubbo Spring Cloud 服务注册中心 Zookeeper Spring Cloud Netfix Eureka 服务监控 Dubbo-monitor Spring Boot Admin 断路器 不完善 Spring Cloud Netfix Hystrix 服务网关 无 Spring Cloud Netfix GateWay 分布式配置 无 Spring Cloud Config 服务跟踪 无 Spring Cloud Sleuth 消息总线 无 Spring Cloud Bus 数据流 无 Spring Cloud Stream 批量任务 无 Spring Cloud Task … … … 4. Dubbo 都支持什么协议，推荐哪种？ 协议 应用场景 优点 缺点 dubbo 适用于高并发小数据量服务调用，特别是消费者数量远大于提供者的情况 减少连接建立和断开的开销，提高性能 对网络稳定性要求高，网络问题可能影响连接 rmi 适合Java应用间的远程服务调用 符合 Java 标准，易于Java 应用集成 存在安全漏洞，不适合大规模分布式系统 webservice 适合需要跨语言交互的系统集成 支持多种编程语言，具有良好的互操作性 性能相对较低，配置相对复杂 http 适用于 Web 服务调用，支持浏览器 JS 调用 基于广泛支持的 HTTP 协议，易于集成 不适合高频率或大数据量的调用 hessian 适用于需要高效二进制序列化的场景 序列化和反序列化速度快，适合大数据传输 维护多个短连接，提供者端可能面临较大压力 memcached 适用于分布式缓存场景，需要快速读写操作 简单高效，读写速度快 主要存储在内存，容量有限，数据易失 redis 适用于需要支持复杂数据结构和持久化的缓存场景 支持多种数据结构，具有持久化选项 相比于 Memcached，资源消耗更大 Thrift 适用于需要高效跨语言服务调用的场景 具有高效的二进制数据传输格式，支持多种编程语言 需要使用 Thrift 的 IDL 来定义服务接口，增加开发复杂性 5. Dubbo 需要 Web 容器吗？ 不需要，如果硬要用 Web 容器，只会增加复杂性，也浪费资源。 6. Dubbo 内置了哪几种服务容器？ Spring Container Jetty Container Log4j Container 7. Dubbo 里面有哪几种节点角色？ 节点 角色说明 Provider 暴露服务的服务提供方 Consumer 调用远程服务的服务消费方 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次数和调用时间的监控中心 Container 服务运行容器 8. 服务注册与发现的流程图 img-3.2 9. Dubbo默认使用什么注册中心，还有别的选择吗？ 推荐使用 Zookeeper 注册中心，还有 Multicast 注册中心，Redis 注册中心，Simple 注册中心。 ZooKeeper 的节点是通过像树一样的结构来进行维护的，并且每一个节点通过路径来标示以及访问。除此之外，每一个节点还拥有自身的一些信息，包括：数据、数据长度、创建时间、修改时间等等。 10. Dubbo 有什么配置方式？ 1）Spring 配置方式 2）Java API 配置方式 11. Dubbo 核心配置有哪些？ 配置 配置说明 dubbo: service 服务配置 dubbo: reference 引用配置 dubbo: protocol 协议配置 dubbo: application 应用配置 dubbo: module 模块配置 dubbo: registry 注册中心配置 dubbo: monitor 监控中心配置 dubbo: provider 提供方配置 dubbo: consumer 消费方配置 dubbo: method 方法配置 dubbo: argument 参数配置 配置之间的关系 img-3.3 12. 在 Provider 上可以配置的 Consumer 端的属性有哪些？ 1）timeout：方法调用超时 2）retries：失败重试次数，默认重试 2 次 3）loadbalance：负载均衡算法，默认随机 4）actives：消费者端，最大并发调用限制 13. Dubbo 启动时如果依赖的服务不可用会怎么样？ Dubbo 缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止 Spring 初始化完成，默认 check=“true”，可以通过 check=\"false\" 关闭检查。 14. Dubbo推荐使用什么序列化框架，你知道的还有哪些？ 推荐使用 Hessian 序列化，还有Duddo、FastJson、Java 自带序列化。 Hessian 原理与协议简析： Hessian 是一种高效的二进制网络传输协议，尽管它遵循 HTTP 协议的基本传输规则，但 Hessian 在数据交换上做了一些优化。 在 Hessian 中，客户端与服务器的通信采用 HTTP POST 方法。这种方式允许在请求中包含更多的数据和信息。 Hessian 利用 HTTP 的头部（header）来传递辅助信息，例如安全授权的 token 等。通过 HTTP 头部，我们可以封装安全校验和元数据等信息。Hessian 还提供了基础的校验机制，以确保数据的完整性。 Hessian 交互的核心数据，包括调用的方法名和参数列表，会以字节流的形式直接在 POST 请求的正文（body）中发送。这种方式提高了数据传输的效率。 服务器端处理请求后，会将响应数据以字节流的形式直接输出到响应（response）中。这种二进制的响应方式，保证了数据的快速传输和解析。 15. Dubbo有哪几种集群容错方案，默认是哪种？ 集群容错方案 说明 Failover Cluster 失败自动切换，自动重试其他服务器（默认） Failfast Cluster 快速失败，立即报错，只发起一次调用 Failsafe Cluster 失败安全，出现异常时，直接忽略 Failback Cluster 失败自动恢复，记录失败请求，定时重发 Forking Cluster 并行调用多个服务器，只要一个成功即返回 Broadcast Cluster 广播逐个调用所有提供者，任意一个报错则报错 16. Dubbo有哪几种负载均衡策略，默认是哪种？ 负载均衡策略 说明 Random LoadBalance（默认） 随机，按权重设置随机概率； 截面碰撞率高，调用次数越多，分布越均匀。 RoundRobin LoadBalance 轮询，按公约后的权重设置轮询比率； 存在请求积累的问题。 LeastActive LoadBalance 最少活跃调用策略，相同活跃数的随机； 解决慢提供者接收更少请求的情况。 ConsistentHash LoadBalance 一致性 Hash，相同参数的请求总是发到同一提供者； 一台机器宕机，可以基于虚拟节点，分摊至其他提供者，避免引起提供者的剧烈变动。 17. 注册了多个同一样的服务，如何测试指定的某一个服务呢？ 可以配置环境点对点直连，绕过注册中心，将以服务接口为单位，忽略注册中心的提供者列表。 18. Dubbo支持服务多协议吗？ Dubbo 允许配置多协议，在不同服务上支持不同协议或者同一服务上同时支持多种协议。 19. 当一个服务接口有多种实现时怎么做？ 当一个接口有多种实现时，可以用 group 属性来分组，服务提供方和消费方都指定同一个 group 即可。 20. 服务上线怎么兼容旧版本？ 可以用版本号（version）过渡，多个不同版本的","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:5:1","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"2. ZooKeeper 1. 什么是 ZooKeeper？ ZooKeeper 主要服务于分布式系统，可以用 ZooKeeper 来做： 命名服务 配置管理 集群管理 分布式锁 队列管理 使用分布式系统就无法避免对节点管理的问题（需要实时感知节点的状态、对节点进行统一管理等等），而由于这些问题处理起来可能相对麻烦和提高了系统的复杂性，ZooKeeper 作为一个能够通用解决这些问题的中间件就应运而生了。 其内核为文件系统和通知机制 2. ZooKeeper 特性 ZooKeeper 的数据结构，跟 Unix 文件系统非常类似，可以看做是一颗树，每个节点叫做ZNode。每一个节点可以通过路径来标识，结构图如下： img-3.4 ZooKeeper 的节点我们称之为 ZNode，并且这些节点都可以设置关联的数据。Zookeeper 为了保证高吞吐和低延迟，在内存中维护了这个树状的目录结构，这种特性使得 Zookeeper 不能用于存放大量的数据，每个节点的存放数据上限为1M。 3. ZNode 的类型： 1）PERSISTENT-持久化目录节点 客户端与 Zookeeper 断开连接后，该节点依旧存在。 2）PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点 客户端与 Zookeeper 断开连接后，该节点依旧存在，只是 Zookeeper 给该节点名称进行顺序编号。 3）EPHEMERAL-临时目录节点 客户端与 Zookeeper 断开连接后，该节点被删除。 4）EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点 客户端与 Zookeeper 断开连接后，该节点被删除，只是 Zookeeper 给该节点名称进行顺序编号。 5. Zookeeper 通知机制 client 端会对某个 ZNode 建立一个 watcher 事件，当该 ZNode 发生变化时，这些 client 会收到 Zookeeper 的通知，然后 client 可以根据 ZNode 变化来做出业务上的改变。 6. Zookeeper 的命名服务（文件系统） 命名服务是指通过指定的名字来获取资源或者服务的地址，利用 Zookeeper 创建一个全局的路径，即是唯一的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。 7. Zookeeper 的配置管理（文件系统、通知机制） 程序分布式部署在不同的机器上，将程序的配置信息放在 Znode 下，当有配置发生改变时，也就是 Znode 发生变化时，可以通过改变 Zookeeper 中某个目录节点的内容，利用watcher通知给各个客户端，从而更改配置。 8. Zookeeper 的集群管理（文件系统、通知机制） 所谓集群管理无在乎两点：是否有机器退出和加入、选举master。 1）机器的退出和加入 所有机器约定在父目录下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 Zookeeper 的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除。新机器加入也是类似，所有其他机器都收到通知：新兄弟目录加入。 2）选举master 所有机器创建临时顺序编号目录节点时，选取编号最小的机器作为 master。 9. Zookeeper 分布式锁（文件系统、通知机制） 有了 Zookeeper 的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。 1）保持独占 将 Zookeeper 上的一个 ZNode 看作是一把锁，通过 CreateZNode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的 distribute_lock 节点就释放出锁。 2）控制时序 假设 /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选 master 一样，编号最小的获得锁，用完删除，依次方便。 10. 获取分布式锁的流程 img-3.5 使用 Zookeeper 实现分布式锁时，客户端首先在指定的 “locker” 节点下创建一个临时顺序节点。这一过程通过调用 createNode 方法完成，该方法在 “locker” 节点下生成一个具有唯一序号的临时节点。 随后，客户端调用 getChildren(\"locker\") 方法来检索 “locker” 节点下的所有子节点，但在此步骤中不设置任何 Watcher，以避免不必要的事件通知。 客户端获取到子节点列表后，会检查自己创建的节点序号是否为列表中的最小值。如果是，客户端便成功获取了锁。如果不是，客户端则需要进一步操作。客户端会找到序号比自己小的最小节点，并对其调用exist()方法，同时注册一个事件监听器。这个监听器的作用是在该节点被删除时接收通知。 一旦被关注的节点被删除，客户端的事件监听器将触发，客户端随即再次检查自己的节点是否已成为\"locker\"子节点中序号最小的节点。如果是，客户端便成功获取了锁；如果不是，客户端需要重复上述步骤，继续寻找并关注比自己节点序号小的下一个节点。 在整个过程中，客户端需要进行一系列的逻辑判断，以确保正确地处理节点的创建、比较、监听和删除等操作。这个过程虽然复杂，但通过 Zookeeper 的有序节点和事件监听机制，可以有效地实现分布式锁的管理和同步。 img-3.6 11. Zookeeper 对列管理（文件系统、通知机制） 队列的定义： 1）同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。 2）队列按照 FIFO 方式进行入队和出队操作。 两种类型的队列： 1）在约定目录下创建临时目录节点，监听节点数目是约定的数目。 2）与分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。在特定的目录下创建 PERSISTENT_SEQUENTIAL 节点，创建成功时 Watcher 通知等待的队列，队列删除序列号最小的节点用以消费。此场景下 Zookeeper 的 ZNode 用于消息存储，ZNode 存储的数据就是消息队列中的消息内容，SEQUENTIAL 序列号就是消息的编号，按序取出即可。由于创建的节点是持久化的，所以不必担心队列消息的丢失问题。 12. Zookeeper 数据复制（文件系统、通知机制） Zookeeper 为一个集群提供一致的数据服务，它在所有机器间做数据复制。 1）数据复制的好处： 容错：一个节点出错，不致于让整个系统停止工作，别的节点可以接管它的工作； 提高系统的扩展能力 ：把负载分布到多个节点上，或者增加节点来提高系统的负载能力； 提高性能：让客户端本地访问就近的节点，提高用户访问速度 2）从客户端读写访问的透明度来看，数据复制集群系统分下面两种： 写主 (WriteMaster)：对数据的修改提交给指定的节点。读无此限制，可以读取任何一个节点。这种情况下客户端需要对读与写进行区别，俗称读写分离； ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:5:2","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Work"],"content":"Reference 2024年吃透经典Java面试题200问，7天学完，让你面试少走99%弯路！！ Java面试+Java后端技术学习指南 Java基础面试16问 MySQL 高频面试题，都在这了 什么是存储引擎以及MySQL常见的三种数据库存储引擎-CSDN博客 前后端分离架构概述-CSDN博客 前后端分离之JWT用户认证 - 简书 老司机总结的12条 SQL 优化方案 MySQL事务，这篇文章就够了 我去！原来单点登录这么简单，这下糗大了！ 史上最全 40 道 Dubbo 面试题及答案，看完碾压面试官！ dubbo 面试18问（含答案） 什么是ZooKeeper？ 负载均衡 - zookeeper面试题 - 个人文章 - SegmentFault 思否 ","date":"2024-06-26","objectID":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/:6:0","tags":["Java","Interview"],"title":"Java后端面试","uri":"/java%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"categories":["Technology"],"content":"如何用 GitHub Pages + Hugo + LoveIt 搭建个人博客 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:0:0","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"1. 概念，搭建思路和运行环境 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:1:0","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"1.1 什么是 GitHub Pages？ GitHub Pages 是 GitHub 提供的免费托管服务，用于托管静态网站。无论是个人、项目还是组织，都可以利用 GitHub Pages 创建和托管网站。 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:1:1","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"1.2 什么是 Hugo? Hugo 是一个快速、现代的静态网站生成器，广泛用于创建博客、公司网站、文档网站等。它以速度和灵活性著称，允许用户使用模板和内容文件生成静态 HTML 文件。 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:1:2","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"1.3 什么是 LoveIt? Hugo 主题 LoveIt 是一个简洁而优雅的主题，专为博客和个人网站设计。它提供了一些关键功能，使用户可以轻松地创建和定制自己的网站。 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:1:3","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"1.4 网站搭建思路 创建 2 个GitHub仓库： 博客源仓库：储存所有 Markdown 源文件（博客内容），和博客中用到的图片等。 GitHub Pages 储存由 Hugo 从 Markdown 文件生成的 HTML 文件。 将博客源仓库中, 由 Hugo 生成的静态 HTML 文件部署到远端 GitHub Pages 仓库中。 目的：将博客源文件单独存放到私有仓库里面，避免访客直接从公共的 GitHub Pages 仓库中获取文章源文件。 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:1:4","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"2. 创建 GitHub 仓库以及本地仓库 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:2:0","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"2.1 创建博客源仓库 进入 GitHub 个人主页，新建博客源仓库。 img-2.1 ✔勾选 Private，设置为私有仓库。 ✔勾选添加 README 文件。 img-2.2 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:2:1","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"2.2 创建GitHub Page 仓库 命名 GitHub Pages 仓库，这个仓库必须使用特殊的命名格式 \u003cusername.github.io\u003e， \u003cusername\u003e 是自己的 GitHub 的用户名。 勾选 Public，设置为公开仓库。 勾选添加 README 文件，这会设置 main 分支为仓库的默认主分支，这在后面提交推送博客内容时很重要。 img-2.3 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:2:2","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"2.3 克隆博客源仓库到本地 打开 git 进入，想要在本地储存项目的文件夹，即源仓库的上级目录（博主这里的路径为 D:\\File\\BlogSorce）。 img-2.4 克隆博客源仓库到项目文件夹，git 输入的指令如下： git clone git@github.com:C6H12O6Mix/Blog.git 最终的克隆结果： img-2.5 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:2:3","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"3. Hugo 的安装和配置 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:3:0","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"3.1 下载安装 Hugo Hugo 官网：https://gohugo.io/ Hugo GitHub 仓库：https://github.com/gohugoio/hugo/releases Hugo 提供了两种版本：标准版本 (standard) 提供了构建网站的基础功能；拓展版本 (extended) 额外还支持 WebP 编码、SASS 等功能（官方建议使用拓展版本）。 点击 Hugo GitHub 仓库：https://github.com/gohugoio/hugo/releases。 根据自己的环境下载发行版 hugo，博主这里下载最新版本的 hugo_extended_0.127.0_windows-amd64.zip。 img-3.1 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:3:1","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"3.2 配置 Hugo 环境 。解压 hugo_extended_0.127.0_windows-amd64.zip。 将其中的 hugo.exe 文件复制到指定文件夹下（可以自定义），如：D:\\System\\Hugo\\bin。 img-3.2 在系统环境变量中，添加上述 hugo.exe 的存放位置，即 D:\\System\\Hugo\\bin。 img-3.2 以管理员身份运行 cmd，输入指令 hugo -help，出现以下结果，则配置成功。 img-3.3 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:3:2","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"4. 使用 Hugo 创建网站 进入刚刚克隆下来的博客源仓库文件夹（比如：博主是在 D:\\File\\BlogSorce ），在这个文件夹里用 Hugo 创建一个网站文件夹（Blog）。 用 Hugo 创建网站文件夹的命令是 hugo new site 网站名字（Blog）。 用 Hugo 创建的网站共有 8 个文件夹和 2 个文件，这些文件分别表示： my-website/ ├── archetypes/ │ └── default.md ├── assets/ ├── content/ ├── data/ ├── i18n/ ├── layouts/ ├── static/ ├── themes/ ├── hugo.toml archetypes/：内容架构目录，作为新内容文件的模板。 default.md：当使用 hugo new /posts/xxx.md 时，Hugo 会基于此生成新文件。 assets/：资源目录，用于存放 SCSS、JavaScript 文件以及其他需要 Hugo Pipes 处理的资源。 content/： 内容目录，存放网站的所有内容文件，包括文章、页面等。可以创建子文件夹来组织内容。 data/： 数据目录，用于存放 YAML、JSON 或 TOML 格式的数据文件。 i18n/： 国际化目录，用于存放 TOML 格式的语言文件，支持多语言。 layouts/： 布局模板目录，包含所有的 HTML 模板文件，定义了网站的结构和布局。 static/： 静态文件目录，存放静态资源文件（如图像、CSS、JavaScript），这些文件在生成网站时将直接复制到公共目录，保持原样提供给浏览器。 themes/： 主题目录，可以将外部主题克隆到这个目录中，或者创建和存放自定义主题。 hugo.toml： 配置文件，包含网站的基本配置选项，例如网站标题、语言、主题等。通常用于设置全局配置，如站点信息、菜单、参数等。 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:4:0","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"5. 安装配置 Hugo 主题 LoveIt ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:5:0","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"5.1 安装 LoveIt 位于博客项目根目录（D:\\File\\BlogSorce\\Blog），输入以下指令： git clone https://github.com/dillonzq/LoveIt.git themes/LoveIt 克隆成功后在 ./themes 文件夹下会出现 LoveIt 文件夹。 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:5:1","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"5.2 LoveIt 关于 hugo.toml 文件的外观参数 配置 ./hugo.toml 文件，可以从 LoveIt 主题的样例文件 ./themes/LoveIt/exampleSite 进行复制和修改，或者进入到 LoveIt 的官方文档 进行查看。 其中部分需要自定义的内容为： # 网站显示的标题，可自定义修改 title = \"xxx\" # 作者信息，可自定义修改 [author] name = \"xxx\" email = \"xxxxxx@xx.com\" # 网站标题栏，可以自定义修改 [params.header] ... [params.header.title] # URL of the LOGO 可以使用 URL 的方式在标题栏添加 logo logo = \"\" # 网站标题栏显示的标题，可以自定义修改 name = \"xxx\" # 打字机特效 typeit = false # 主页个人信息 [params.home] ... [params.home.profile] ... # 将头像图片放置于项目根目录下的 ./assets/images, 并命名为 avatar.png avatarURL = \"/images/avatar.png\" # 主标题-个人名称 title = \"xxx\" # 副标题-简述 subtitle = \"xxxxxx\" # 显示在主页的个人社交链接，按需填写 [params.social] GitHub = \"\" Twitter = \"\" ... ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:5:2","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"6. 用 Hugo 创建文章 推荐写法：在博客项目根目录，输入以下命令（注意文件名不要输入空格或者其他特殊字符）： hugo new ./posts/新建文件夹(最好命名为文章主题)/index.md 使用这个命令后会在 ./content/posts/新建文件夹 下创建 idex.md 文件，并且会套用套用 archetypes 文件夹中的 default.md 模版。 之所以用 hugo new ./posts/新建文件夹/index.md，而不直接使用 hugo new 文章主题.md 是方便后续在博客中插入图片使用相对路径。 例如：想要在博客文章中插入一张图片 img-01.png，又不想使用图床，可以利用上述创建的新建文件夹，通过相对路径来插入图片。 在文件夹下 创建 img（名称自拟）文件夹，然后文章中想要插入的位置输入。 \u003cimg src=\"img/img-01.png\"/\u003e ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:6:0","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"7. 本地调试和预览 在发布到网站前可以在本地预览网站或内容的效果，运行命令： hugo server 也可以在本地编辑 Markdown 文件时，通过 hugo server 来实时预览显示效果。 hugo server 运行成功后，可以在 http://localhost:1313/ 中预览 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:7:0","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"8. 发布内容 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:8:0","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"8.1 GitHub Actions 原理 GitHub Actions 是一种 CI/CD 工具（Continuous Integration-持续集成，Continuous Deployment-持续部署或Continuous Delivery-持续交付），能够在特定事件发生时自动执行预定义的任务。 工作原理 触发事件（Triggers）：特定事件（如代码提交、pull request）触发 GitHub Actions。 工作流（Workflows）：事件触发后，Actions 按 .github/workflows 目录下定义的工作流执行任务。 任务（Jobs）：任务包含多个步骤（steps），在独立的虚拟环境中运行。 步骤（Steps）：步骤是具体操作，如运行命令、执行脚本等。 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:8:1","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"8.2 生成 Actions secrets 生成 Personal access tokens 首先点击 GitHub 头像在下拉栏里进入 Setting -\u003e Developer Settings -\u003e Personal access tokens -\u003e Tokens (classic) img-8.1 点击 Generate token，Note 的内容可以随心填写；Expiration 为 token 过期时间，这里直接拉满，选择永不过期；Select scope 为 token 权限，这里选择 repo，和 admin:repo_hook img-8.2 点击 Generate token 生成 token， 记住一定要复制保存，该 token 只显示一次。 进入博客源仓库的 Setting -\u003e Secrets and variables -\u003eActions 一栏，点击 New respository secret img-8.2 ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:8:2","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"8.3 配置 acitons 文件 在本地源仓库文件夹的根目录新建两个文件夹 ./.github/workflows，在 workflows 里新建一个后缀为 xxx.yml 的配置文件，其中名字自取，这里暂时命名为 ghpages.yml。 img-8.3 修改 ghpages.yml 的配置，其中需要修改的部分： external_repository： 修改为自己的 GitHub page 仓库 personal_token：${{ secrets.XXX }} XXX 修改成上面生成 Actions secrets 步骤中取得的名称。 name: github pages # 名字自取 on: push: branches: - main # 这里的意思是当 main分支发生push的时候，运行下面的jobs，这里先改为github-actions jobs: deploy: # 任务名自取 runs-on: ubuntu-latest # 在什么环境运行任务 steps: - uses: actions/checkout@v2 # 引用actions/checkout这个action，与所在的github仓库同名 with: submodules: true # Fetch Hugo themes (true OR recursive) 获取submodule主题 fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo # 步骤名自取 uses: peaceiris/actions-hugo@v2 # hugo官方提供的action，用于在任务环境中获取hugo with: hugo-version: 'latest' # 获取最新版本的hugo # extended: true - name: Build run: hugo --minify # 使用hugo构建静态网页 - name: Deploy uses: peaceiris/actions-gh-pages@v3 # 一个自动发布github pages的action with: # github_token: ${{ secrets.GITHUB_TOKEN }} 该项适用于发布到源码相同repo的情况，不能用于发布到其他repo external_repository: C6H12O6Mix/c6h12o6mix.github.io # 发布到哪个repo personal_token: ${{ secrets.BLOG_ACTION }} # 发布到其他repo需要提供上面生成的personal access token publish_dir: ./public # 注意这里指的是要发布哪个文件夹的内容，而不是指发布到目的仓库的什么位置，因为hugo默认生成静态网页到public文件夹，所以这里发布public文件夹里的内容 publish_branch: main # 发布到哪个branch ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:8:3","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"8.4 推送代码到源仓库 注意：在推送代码之前，需要将 ./themes/LoveIt 下的 .git 以及 .github 文件夹的内容。否则，GitHub 会将 LoveIt 文件夹识别为子模块，导致 GitHub Action 在部署时，无法识别 ./themes/LoveIt 下的文件，从而部署失败。 将 Blog 文件夹初始化为 Git 仓库，并设置默认主分支为 main。这么做的原因是：GitHub 创建仓库时生成的默认主分支名是 main 用 git init 初始化 Git 仓库时创建的默认主分支名是 master 将 git init 创建的 master 修改成 main ，再推送给远端仓库，这样才不会报错。 git init -b main 将 public 文件夹关联远程 GitHub Pages 仓库，使用 GitHub Pages 仓库的 SSH 链接。 git remote add origin git@github.com:C6H12O6Mix/Blog.git 推送本地文件到远程仓库 git pull --rebase origin main git add . git commit -m \"...(修改的信息)\" git push origin main 推送完成之后到 GitHub 仓库中的 Actions 中就可以看到 runs 运行成功，然后可以通过类似以下链接，访问你的博客了。 https://c6h12o6mix.github.io/ ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:8:4","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"},{"categories":["Technology"],"content":"Reference 如何用 GitHub Pages + Hugo 搭建个人博客 · KrislinBlog ","date":"2024-06-24","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/:9:0","tags":["Hugo","GitHub Pages","Blog Builder","LoveIt"],"title":"搭建博客 Github+Hugo+LoveIt","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2github-hugo-loveit/"}]