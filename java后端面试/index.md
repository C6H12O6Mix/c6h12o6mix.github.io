# Java后端面试


## Java 后端初步学习

<br>

## 一、基础核心

### 1. 线程

#### 1.1 java 线程创建方式

> **1) 继承 Thread 类**
>
> 重写的是 run() 方法，而不是 start() 方法，但是占用了继承的名额，Java 中的类是单继承的 

```java
public class ThreadImpl extends Thread {
    
    public static void main(String[] args) {
        ThreadImpl thread = new Thread();
        thread.start();
    }
    
    @Override
    public void run() {
        System.out.println("hello world!")
    }
}
```

> **2) 实现 Runnable 接口**
>
> 利用接口的多继承特性，创建线程，实现 run() 方法

```java
public class ThreadImpl implements Runnnable {
    
    public static void main(String[] args) {
        Thread thread = new Thread(new ThreadImpl());
        thread.start();
    }
    
    public void run() {
        System.out.println("hello world!");
    }
}
```

>**3) 实现 Callable 接口**
>
>上述两种方法均不能实现 run() 方法返回值，而实现 Callable 接口中的 call() 方法 (需要 Tread + Future 配合) ，支持拿到异步执行任务的结果

```java
public class ThreadImpl implements Callable<String> {
    
    public static void main(Sting[] args) {
        FutureTask<String> futureTask = new FutureTask<>(new ThreadImpl());
        Thread thread = new Thread(futureTask);
        thread.start();
        String result = futureTask.get();
        System.out.println(result);
    }
    
    public String call() {
        return "hello world!";
    }
}
```

> **4) 利用线程池来创建线程**
>
> 此方法通过实现 Callable 接口或是 Runnable 接口均可，由 ExecutorService 来创建线程

```java
public class ThreadImpl implements Runnable {
    
    public static void main(String[] args) throws ExecutionException {
        ExcutorService executorService = Executors.newFixedThreadPool(10);
        executorService.execute(new ThreadImpl());
    }
    
    public void run() {
        System.out.println("hello world!");
    }
}
```

> **总结**
>
> 以上四种方法的底层都是基于 Runnable

#### 1.2 为什么不建议使用 Executors 来创建线程池

**1. FixedThreadPool**

当我们使用 Executors 创建 FixedThreadPool 时，对应的构造方法为：

```java
public static ExecutorService new FixedThreadPool(int nThreads) {
    return new ThreadPoolExecutor(nThreads, nThreads,
                                 0L, TimeUnit.MILLISECONDS,
                                 new LinkedBlockingQueue<Runnable>());
}
```

发现创建的队列为 LinkedBlockingQueue，是一个无界阻塞队列。

假设使用该方法创建 nThread=10 线程池执行任务，遇到任务过多的情况就会不断添加到队列中，最终导致内存溢出 OOM。

**2. SingleThreadExecutor**

当我们使用 Excutors 创建 SingleTheadExcutor 时，对应的构造方法为：

```java
public static ExecutorService new SingleThreadExecutor() {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExcutor(1, 1,
                              0L, TimeUnit.MILLISECONDS,
                              new LinkedBlockingQueue<Runnable>()));
}
```

#### 1.3 线程池的状态

> <center><img src="pic/img-23.png" width="960"/></center>

<center><font color=silver>img-1.1</font></center>

```java
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, wc: 0));
private static final int COUNT_BITS = Interger.SIZE - 3;
private static final int CAPACITY = (1 << COUNT_BITS) - 1;

// runState is stored in the high-order bits
private static final int RUNNING = -1 << COUNT_BITS;
private static final int SHUTDOWN = 0 << COUNT_BITS;
private static final int STOP = 1 << COUNT_BITS;
private static final int TIDYING = 2 << COUNT_BITS;
private static final int TERMINATED = 3 << COUNT_BITS;

// Packing and unpacking ctl
private static int runStateOf(int c) {return c & ~CAPACITY;}
private static int workerCountOf(int c) {return c & CAPACITY;}
private static int ctlOf(int rs, int wc) {return rs | wc;}
```

`ctl` 作为一个 4 字节的整型变量，32 位 bit 位，高 3 位用来存储线程池的状态 **RUNNING、SHUTDOWN、STOP、TIDYING、TERMINATED**。剩下的 29 位用来存储线程池数量。

#### 1.4 Sychronized 和 ReentrantLock 有哪些不同点？

| Sychronized                      | ReentrantLock                                                |
| -------------------------------- | ------------------------------------------------------------ |
| Java 中的一个关键字              | JDK 提供的一个类                                             |
| JVM 层面上的锁                   | API 层面的锁                                                 |
| 自动加锁与释放锁                 | 需要手动加锁与释放锁                                         |
| 不可获取当前线程是否上锁         | 可获取当前线程是否上锁<br />isHeldByCurrentThread            |
| 非公平锁                         | 公平锁或非公平锁（可通过参数设置）                           |
| 不可中断                         | 可中断<br />1. 调用设置超时方法 tryLock(long timeout, timeUnit unit)<br />2. 调用 lockInterruptibly() 放到代码块中，然后调用 interrupt() 方法可以中断 |
| 锁的是对象，锁信息保存在对象头中 | int 类型的 state 标识来标识锁的状态                          |
| 底层有锁升级过程                 | 没有锁升级过程                                               |

#### 1.5 ThreadLoal 有哪些应用场景？它的底层如何实现？

**1. ThreadLocal 机制**

ThreadLocal 是 Java 中所提供的线程本地存储机制，可以利用该机制将数据**缓存在某个线程内部**，该线程可以在任意时刻、任意方法中获取缓存中的数据。

> <center><img src="pic/img-24.png" width="960"/></center>

<center><font color=silver>img-1.2</font></center>

**2. ThreadLocal 和 ThreadLocalMap**

ThreadLocal 底层是通过 ThreadLocalMap 来实现的，每个 Thread 对象中都存在一个 ThreadLocalMap，Map 的 key 为 ThreadLocal 对象，Map 的 value 为需要的缓存值。

```javaThd
/* ThreadLocal values pertaining to this thread. This map is maintained by the ThreadLocal Class.*/
ThreadLocal.ThreadLocalMap threadLocals = null;
```

**3. ThreadLocal 存在的局限**

如果在线程池中使用 ThreadLocal 会造成内存泄露，因为当 ThreadLocal 对象使用完之后，应该要把设置的 key，value，也就是 Entry 对象进行回收。但线程池中的线程本身不会被不会回收，而线程对象是通过强引用指向 ThreadLocalMap，ThreadLocalMap 也是通过强引用指向 Entry 对象，线程不被回收，导致强引用的数据不会被垃圾回收，从而出现内存泄漏。

解决办法是，在使用了 ThreadLocal 对象之后，手动调动 ThreadLocal 的 remove 方法，手动清除 Entry 对象。

**4. ThreadLocal 的应用场景**

当一个共享变量是共享的，但是需要每个线程互不影响，相互隔离，就可以使用 ThreadLocal

- 跨层传递信息的时候，每个方法都申明一个参数很麻烦，A、B、C、D 四个类相互传递，每个方法都声明参数降低了维护性，可以用一个 ThreadLocal 共享变量，在 A 存值，BCD 都可以获取。
- 隔离线程，存储一些不安全的工具对象，如（SimpleDateFormat）
- Spring 中的事务管理器就是使用的 ThreadLocal
-  SpringMVC 的 HttpServletRequest、HttpServletReesponse 都是放在ThreadLocal， 因为 servlet 是单例的，而 SpringMVC 允许在 controller 类中通过 @Autowired 配置 Request、Response 以及 RequestContext 等实例对象。底层就是搭配 ThreadLocal 才实现线程安全。

**5. ReentrantLock 分为公平锁和非公平锁，那底层分别是如何实现的？**

首先不管是公平锁和非公平锁，他们的底层实现都会使用 AQS 来进行排队，他们的区别在于线程在使用 lock() 方法加锁时：

- 如果是公平锁，会先检查 AQS 队列中是否存在线程在排队，如果有线程在排队，则当前线程也进行排队
- 如果是非公平锁，则不会去检查是否有线程在排队，而是直接竞争锁。

不管是公平锁还是非公平锁，一旦没竞争到锁，都会进行排队，当锁释放时，都是唤醒排在最前面的线程，所以非公平锁只是体现在了线程加锁阶段，而没有体现在线程被唤醒阶段。

> ReentranLock 是可重入锁（同一个线程可以重复获取锁的对象），不管是公平锁还是非公平锁都是可重入的。

<br>

### 2. 虚拟机

#### 2.1 虚拟机结构

**1. 类加载器**

**1) 类加载器的类别**

- **启动类加载器：**负责加载 Java 核心类，它是 Java 虚拟机的一部分，负责最基础和最核心的类加载任务。
- **扩展类加载器：**用于 Java 扩展目录的类，它扩展了 Java 的核心功能，允许开发人员和第三方供应商提供额外的类库。
- **应用程序类加载器：**加载我们自己编写的 Java 类，负责加载应用程序的类路径上的类。

**2) 类加载机制有两种主要的委派机制**

1. **双亲委派机制：**当一个类加载器收到加载类的请求时，它会先委托给父加载器去加载。这种机制保证了类加载的顺序和一致性，避免重复加载。例如，应用程序类加载器加载一个类时，会先委托给扩展类加载器，然后扩展类加载器再委托给启动类加载器，直到核心类库，如果找不到则返回到应用程序类加载器。
2. **全盘负责委托机制：**在这种机制下，当一个类加载器负责加载某个类时，它会负责加载该类的所有依赖。如果没有显式指定使用另一个加载器，当前加载器会尝试加载所有相关的类。这种方式相对简单直接，但可能导致类冲突和资源浪费。

**2.  堆存储类变量**，当栈需要调用类变量时，栈中局部变量表存储的类变量指针会指向堆的类变量。

**3. 栈存储**局部变量表、操作数栈、动态链接、方法出口等

**4. 方法区/原空间存储**常量、静态变量、类信息（若静态变量等也是类变量，那么方法区也将存放的是类变量的指针，指向堆中的类变量）

> <center><img src="pic/img-17.png" width="960"/></center>

<center><font color=silver>img-1.1</font></center>

#### 2.2 栈

```java
public class Demo {
    
    public int test() {
        int a = 1;
        int b = 2;
        int c = a + b;
        return c;
    }
    
    public static void main(String[] args) throws IOException {
        Demo demo = new Demo();
        demo.test();
        System.out.println("end");
    }
}
```

针对上述程序，其栈存储下图所示：

> <center><img src="pic/img-18.png" width="960"/></center>

<center><font color=silver>img-1.2</font></center>

#### 2.3 JVM 参数

假设我们有一个亿级流量电商的网站，其中日活用户 500 万，日均 50 万单。在日常情况下，订单为每秒几十单，但是遇到平台商家的大促活动时，订单可达每秒 1000 多单，假设订单平均分摊在 4 核 8 G 的服务器上，这时候很容易产生内存溢出 OOM 的情况。

假定每个订单对象的大小为 1KB，每秒就是 300KB 订单对象生成，下单还涉及其他对象和操作，综合下来每秒就是 60 MB 大小的对象，在一秒后都变成垃圾对象。

> <center><img src="pic/img-21.png" width="960"/></center>

<center><font color=silver>img-1.3</font></center>

具体的运行时数据区的内存模型如下，线程每秒产生 60MB 对象，运行十四秒就将占满 enden 区，出发 minor gc 进行垃圾回收处理。但是运行 minor gc 时，某线程有可能还在执行，并且其指向 enden 区的对象，这时 minor gc 不会清理线程指向的对象，而是把对象传递到 Survivor 区，甚至有可能直接传递到老年区（60MB 大于 Survivor 区 100 MB * 1/2，会直接传递到老年代）。

不出几分钟，存活期理应只有 1 秒的对象，就会填满老年区，导致内存溢出触发 full gc。

可以通过，调整老年代和新生代的内存规模：

| enden        | S0           | S1           | Tenured  |
| ------------ | ------------ | ------------ | -------- |
| 800M -> 1.6G | 100M -> 200M | 100M -> 200M | 2G -> 1G |

> <center><img src="pic/img-22.png" width="960"/></center>

<center><font color=silver>img-1.4</font></center>

<br>

### 3. GC 算法

> GC 是 JVM 自动`内存管理` 的重要组成部分。主要包括标记-清除、标记-整理、复制算法和分代收集算法。
>
> 1. **标记-清除算法：**分为两个阶段，首先标记所有需要回收的对象，然后统一回收所有被标记的对象。它是最基础的收集算法。
> 2. **标记-整理算法：**与标记-清除算法类似，首先进行标记阶段，在清理阶段不是简单地回收对象，而是让所有存活的对象向一端移动，然后直接清理掉边界以外的内存。这样可以减少内存碎片化。
> 3. **复制算法**：这种算法将内存分为两块大小相等的区域，每次只使用其中的一块。当一块内存区域的对象存活时间结束时，将存活的对象复制到另一块区域中，然后清理掉该块区域。这样做的好处是每次回收时只需对其中一半的内存空间进行操作，减少了碎片化问题。

#### 3.1 为什么使用 GC

堆内存在 Java 等编程语言中是一种重要的内存区域，用于存储对象示例和数组。堆内存的结构通常包括以下几个关键部分：

1. **新生代（Young Generation）：**新创建的对象首先会被分配到新生代中。新生代通常被进一步分为 Eden 空间和两个 Survivor 空间（通常称为 From 和 To 区或者 S0 和 S1 区）。大多数对象在新生代中很快变得不可达并被垃圾回收器收集。
2. **老年代（Old Generation）：**新生代中新生代中经历多次垃圾回收仍然存活的对象会被移动到老年代。老年代用于存储生命周期较长的对象，通常会被更慎重地回收。
3. **永久代（或原空间，Permanent Genration / Metaspace）**在较早版本的 Java 中存在永久代，用于存储类的元数据、常量池等。在现代的 Java 版本中，永久代被元空间（Metaspace）取代，元空间使用本地内存来存储这些数据，因此不再有固定大小的限制，而且垃圾收集的方式也不同于堆内存。

> <center><img src="pic/img-19.png" width="960"/></center>

<center><font color=silver>img-1.3</font></center>

#### 3.2 垃圾回收器

JVM提供了多种垃圾回收器，包括 Serial、ParNew、Parallel Scavenge、Serial Old、Parallel Old、CMS 和 G1 等。每种收集器适用于不同的应用场景，开发者可以根据应用特点选择合适的垃圾回收器。

**1. Serial 收集器**

Serial 收集器通过复制算法来处理新生代，而老年代则使用标记-整理算法。该收集器利用**单线程**进行垃圾回收，因此在回收过程中会直接中断所有程序线程，实施全局停顿（Stop-The-World）。

**2. ParNew 收集器**

ParNew 收集器主要用于新生代，采用复制算法进行垃圾回收，而老年代则使用标记-整理算法。它利用**多线程**来处理垃圾回收，在进行回收时，应用程序仍会经历中断。

**3. Parrallel Scavenge 收集器**

Parrallel Scavenge 收集器专为吞吐量优先的应用程序设计，其新生代采用复制算法进行垃圾回收，而老年代采用标记-整理算法。与 ParNew 收集器相似，也是利用多线程来处理垃圾回收工作。

Serial Old 收集器和 Parallel Old 收集器分别是 Serial 收集器和 Parallel Scavenge 收集器的老年代版本。它们可以看作是将老年代的垃圾回收算法单独提取出来，以便于其他收集器的新生代部分组合使用。

**4. CMS 收集器**

CMS 收集器 （Concurrent Mark-Sweep 收集器）在启动垃圾回收时，首先快速获取于根节点直接相连的对象，因此停顿时间比较短。随后，它与应用程序竞争 CPU 资源，进行并发标记阶段，识别仍然可达的对象。随着并发标记的进行，新生成的对象会在后续的短暂停顿期间被标记。最终，在清理阶段，CMS 收集器会清理那些没有被标记的空间内存。

> <center><img src="pic/img-20.png" width="960"/></center>

<center><font color=silver>img-1.4</font></center>

**5. G1 收集器**

G1 收集器将 Java 堆划分为多个大小相等的独立区域（Region）。虽然保留了新生代和老年代的概念。但它们不再是物理上的隔离，而是由许多**可能并不连续**的 Region 组成的集合。G1 收集器允许大对象直接分配到 Humongous 区域，这些区域专门用于存放**短期的巨型对象**，避免了因为无法找到连续空间而提前出发下一次GC，从而减少了 Full GC 所带来的大量开销。

在 G1 收集器中，除了将 Java 堆划分为多个大小相等的独立区域（Region）外，还实现了筛选回收的过程。用户可以指定回收时间，因此 JVM 会评估回收成本并制定回收计划，以优先回收堆系统性能影响较大的对象。

<br>

### 4. Tomcat

#### 4.1 Tomcat 中为什么要使用自定义类加载器

一个 Tomcat 中可以部署多个应用，而每个应用中都存在很多类，并且各个应用中的类是独立的，全类名是可以相同的，比如一个订单系统中可能存在 com.demo.User 类，一个库存系统中可能也存在 com.demo.User 类。

一个 Tomcat，不管内部部署了多少个应用，Tomcat 启动之后就是一个 Java 进程，也就是 JVM，所以如果 Tomcat 中只存在一个类加载器，比如默认的 AppClassLoader，那么就只能加载一个 com.demo.User 类，这是有问题的。

而在 Tomcat 中，会为部署的每个应用都生成一个类加载器实例，名字叫做 WebAppClassLoader，这样 Tomcat 中每个应用就可以使用自己的类加载器去加载自己的类，从而达到应用之间的类隔离，不出现冲突。另外 Tomcat 还利用自定义加载器实现了热加载功能。

<br>

### 5.  Java 基础面试 16 问

**1. 进程和线程的区别**

进程是程序的一次执行，是系统进行资源分配和调度的独立单位，他的作用是使程序能够并发执行提高资源利用率和吞吐率。
由于进程是资源分配和调度的基本单位，且进程的创建、销毁、切换会产生大量的时、空开销。故提出线程概念，线程是比进程更小的，并能独立运行的基本单位。他是进程的一个实体，可以减少程序并发执行时的开销，使得操作系统具有更好的并发性。
线程基本不拥有系统资源，只有一些运行时必不可少的资源，比如程序计数器、寄存器和栈，进程则占有堆、栈。

**2. synchronized 原理**

synchronized 是 java 提供的`原子性内置锁`，这种内置的且透明的锁也被称为**监视器锁**，使用 synchronized 之后，会在编译之后在同步的代码块前后加上 monitorenter 和 monitorexit 字节码指令，他依赖操作系统底层互斥锁实现。他的作用主要就是实现原子性操作和解决共享变量的内存可见性问题。

synchronized 的具体实现流程：

- 执行 monitorenter 指令时会尝试获取对象锁，如果对象没有被锁定或者已经获得了锁，锁的计数器 + 1。此时其他竞争锁的线程则会进入等待队列中。
- 执行 monitorexit 指令时则会把计数器 - 1，当计数器值为 0 时，则锁释放，处于等待队列中的线程再继续竞争锁。
- synchronized 是排它锁，当一个线程获得锁之后，其他线程必须等待该线程释放锁后才能获得锁，而且由于 Java 中的线程和操作系统原生线程是一一对应的，线程被阻塞或者唤醒时会从用户态切换到内核态，这种转换非常消耗性能。
- 从内存语义来说，加锁的过程会清除工作内存中的共享变量，再从主内存读取，而释放锁的过程则是将工作内存中的共享变量写回主内存。

如果再深入到源码来说，synchronized 实际上有两个队列 waitSet 和 entryList

1. 当多个线程进入同步代码块时，首先进入 entryList
2. 有一个线程获取到 monitor 锁后，就将自己赋值给当前线程，并使得计数器 + 1
3. 如果线程调用 wait 方法，将释放锁，当前线程置为 null，计数器 - 1，同时进入 waitSet 等待被唤醒，调用 notify 或者 notifyAll 之后有会进入 entryList 竞争锁
4. 如果线程执行完毕，同样释放锁，计数器 - 1，当前线程置为 null

> <center><img src="pic/img-12.png" width="960"/></center>

<center><font color=silver>img-1.1</font></center>

**2. 锁的优化机制**

优化机制包括自适应锁、自旋锁、锁消除、锁粗化、轻量级锁和偏向锁。
锁的状态从低到高依次为**无锁->偏向锁->轻量级锁->重量级锁**，升级的过程就是从低到高，降级在一定条件也是有可能发生的。

**1）自旋锁：**

由于大部分时候，锁以及共享变量被占有的时间非常短，所有没有必要挂起线程。自旋锁的核心概念就是当一个线程尝试获取一个已经被其他线程持有的锁时，它不会立即进入睡眠状态，而是在当前位置循环（自旋）等待锁的释放。其主要特点如下：

1. **非阻塞性：**自旋锁不会使线程进入睡眠状态，而是让线程在当前位置循环等待，直到锁被释放。
2. **适用于锁持有时间短的场景**：如果锁的持有时间很短，自旋锁可以减少线程从睡眠到唤醒的开销，提高效率。
3. **避免线程切换开销**：由于线程不会进入睡眠状态，因此避免了线程切换的开销，这在某些高并发场景下是有利的。
3. **可能导致CPU资源浪费**：如果锁被长时间持有，自旋锁会导致等待的线程占用CPU资源进行无意义的循环，从而降低系统的整体性能。
3. **超时机制**：自旋锁通常在实现时会有一个超时机制，如果在超时时间内锁没有被释放，线程可以选择放弃自旋，进入睡眠状态，以避免无限期地占用CPU资源

**2）自适应锁：**

自适应锁就是自适应的自旋锁，自旋的时间不是固定时间，而是由前一次在同一个锁上的自旋时间和锁的持有者状态来决定。

**3）锁消除：**

锁消除指的是JVM检测到一些同步的代码块，完全不存在数据竞争的场景，也就是不需要加锁，就会进行锁消除。

**4）锁粗化：**

假设有一个多线程程序，其中多个线程需要频繁访问一个共享数据结构。如果每个线程访问时都使用独立的锁，可能会导致频繁的锁争用和上下文切换。通过锁粗化，可以将这些锁合并为一个更大的锁，使得所有线程在访问数据结构时都使用同一个锁，从而减少锁的争用和上下文切换。锁粗化除了可以通过合并锁，具体还可以通过扩大锁的范围，使得更多的操作在锁的保护下执行，减少锁的获取和释放次数。

**5）偏向锁：**

当一个线程首次访问同步代码块时，JVM 会将这个锁标记为偏向当前线程，并将线程 ID 记录在对象头中。如果后续访问仍然是同一个线程，那么这个线程不需要进行任何同步操作，直接进入同步代码块，因为 JVM 认为这个线程是这个锁的偏向所有者。若有其他线程尝试访问同一个同步代码块，JVM 会撤销偏向状态，并将锁升级为轻量级乃至重量级锁。其适用场景：

1. **单线程程序**：在单线程程序中，偏向锁可以显著提高性能。
2. **低并发多线程程序**：在多线程竞争不激烈的情况下，偏向锁可以提高程序的运行效率。

> 可以通过 JVM 参数来启用或者禁用偏向锁：
>
> - `XX:+UseBiasedLocking`：启用偏向锁（默认启用）。
> - `XX:-UseBiasedLocking`：禁用偏向锁。

**6）轻量级锁**

轻量级锁是一种基于 CAS (Compare-And-Swap) 操作的锁机制，它主要用于减少线程在获取锁时的开销。当线程首次访问同步代码块时，JVM 会检查锁对象的 Mark Word（对象头）是否指向当前线程。如果是，表示当前线程已经持有锁，可以直接进入同步代码块。如果不是，JVM 会尝试使用 CAS 操作将锁对象的 Mark Word 替换为当前线程的指针。如果CAS操作成功，表示当前线程成功获取了锁；如果失败，则表示锁已经被其他线程持有。

**适用场景：**

- 适用于锁竞争不激烈且线程持有锁的时间较短的场景。
- 可以减少线程在获取锁时的上下文切换和阻塞。

**7）重量级锁**

重量级锁是一种基于操作系统互斥量的锁机制。它主要用于处理高并发场景下的锁竞争。当线程尝试获取锁时，如果锁已经被其他线程持有，JVM 会将当前线程阻塞，并将其加入到锁对象的等待队列中。持有锁的线程在释放锁时，会唤醒等待队列中的线程，这些线程会重新尝试获取锁。重量级锁涉及到操作系统层面的线程阻塞和唤醒，因此开销较大。

> 锁的升级机制

1. **无锁状态：**初始状态，对象没有被锁定，没有线程进入同步代码块。
2. **偏向锁：**当线程首次访问同步代码块时，JVM 会将对象头的 Mark Word 标记为偏向当前线程，实现无锁竞争。、
3. **轻量级锁**：如果多个线程尝试访问同一个同步代码块，JVM 会撤销偏向锁，将对象头复制到当前线程的栈中，并尝试使用 CAS 操作将对象头指向栈中的锁记录，实现轻量级锁。
4. **重量级锁**：如果轻量级锁状态下发生严重的锁竞争，或者锁被长时间持有，JVM 会将轻量级锁升级为重量级锁，此时涉及到操作系统层面的线程阻塞和唤醒。

> 锁升级条件

- **多个线程竞争**：当多个线程尝试获取同一个锁时，JVM 会考虑升级锁的状态。
- **自旋失败**：在轻量级锁状态下，如果 CAS 操作尝试失败，JVM 会进行一定次数的自旋，如果自旋后仍然无法获取锁，JVM 会考虑升级锁。
- **长时间持有**：如果锁被长时间持有，JVM会认为轻量级锁无法满足当前的并发需求，从而升级为重量级锁。

> 锁升级流程图

> <center><img src="pic/img-13.png" width="960"/></center>

<center><font color=silver>img-1.2</font></center>

**3. 在 HotSport 虚拟机中，对象的内存布局主要包括**

**1）对象头（Header）**

- 包含两部分信息：
  - **Mark Word：**用于存储对象的 hashCode、锁状态标志、线程持有锁的 ID、GC 分代年龄等信息。
  - **类型指针：**指向对象的类定义的指针，即指向元数据的方法表（Method Table），它用于动态方法分派。

**2）实例数据（Instance Data）**

- 存储实际的类字段信息，包括父类的字段和子类中定义的字段。这部分的存储顺序受字段在 Java 源码中定义的顺序影响，但可能经过 JVM 的优化调整。

**3）填充数据（Padding）**

- 对齐填充，HotSpot JVM 要求对象的起始地址必须是 8 字节的倍数。填充数据用于确保对象的内存地址满足对齐要求。

**4）数组长度（对于数组对象）**

- 如果对象是数组类型，那么对象头中还包含一个数组长度的字段，用于存储数组的长度。

**5）对齐要求**

- HotSpot JVM 要求对象的大小必须是 8 字节的整数倍，这是为了满足对象访问的效率和内存对齐的要求。

**4. ReentrantLock 原理，以及和 synchronized 的区别**

相比于 synchronized，ReentrantLock 需要显式的获取锁和释放锁，相对现在基本都是用 JDK7 和 JDK8 的版本，ReentrantLock 的效率和 synchronized 区别基本可以持平了。他们的主要区别有以下几点：

1. 等待可中断，当持有锁的线程长时间不释放锁的时候，等待中的线程可以选择放弃等待，转而处理其他的任务。
2. 公平锁：synchronized 和 ReentrantLock 默认都是非公平锁，但是 ReentrantLock 可以通过构造函数传参改变。只不过使用公平锁的话会导致性能急剧下降。
3. 绑定多个条件：ReentrantLock 可以同时绑定多个 Condition 条件对象。

> ReentratLock 基于 AQS（Abstract Queued Synchronizer 抽象队列同步器）实现，AQS 的原理如下：

AQS 内部维护一个 state 状态位，尝试加锁的时候通过 CAS（Compare And Swap）修改值，如果成功设置为 1，并且把当前线程 ID 赋值，一旦获取到锁，其他的线程将会被阻塞进入阻塞队列自旋，获得锁的线程释放锁的时候将会唤醒阻塞队列中的线程，释放锁的时候则会把 state 重新置为 0，同时当前线程 ID 置为空。

> <center><img src="pic/img-14.png" width="960"/></center>

<center><font color=silver>img-1.3</font></center>

**4. CAS 的原理**

CAS（Compare And Swap），主要是通过处理器的指令来保证操作的**原子性**，它包含三个操作数：

1. 变量内存地址，V 表示
2. 旧的预期值，A 表示
3. 准备设置的新值，B 表示

当执行 CAS 指令时，只有当 V 等于 A 时，才会用 B 去更新 V 的值，否则就不会执行更新操作。

**5. CAS 的主要缺点**

- **ABA 问题：**ABA 的问题指的是在 CAS 更新的过程中，当读取到的值是 A，然后准备赋值的时候仍然是 A，但是实际上有可能 A 的值被改成了 B，然后又被改回了 A，这个 CAS 更新的漏洞就叫做 ABA。只是 ABA 的问题大部分场景下都不影响并发的最终效果。
  Java 中有 Atomic Stamped Reference 来解决这个问题，即利用新增的`预期标志`和`更新后标志`两个字段，检查更新值以及当前标志是否等于预期标志，全部相等的话才会更新。
- **循环时间长开销大：**自旋 CAS 的方式如果长时间不成功，会给 CPU 带来很大的开销。
- **只能保证一个共享变量的原子操作**：只对一个共享变量操作可以保证原子性，但是多个则不行，多个可以通过 Atomic Reference 来处理或者使用锁 synchronized 实现。

**6. HashMap 的原理**

HashMap 主要由数组和链表组成，它不是线程安全的。核心的点就是 put 插入数据的过程，get 查询数据以及扩容的方式。JDK1.7 和 1.8 的主要区别在于头插和尾插方式的修改，头插容易导致 HashMap 链表死循环，并且 1.8 之后加入红黑树对性能有提升。

> put 插入数据流程

1. **哈希定位：**使用键（Key）的哈希码通过位运算（`(n-1) & hash`）来确定元素在数组中的位置。这里 `n` 是数组长度，它总是 2 的幂，因此这种位运算实际上和取模运算（`hash % n`）效果相同，但位运算在效率上更胜一筹。
2. **元素存储：**一旦确定了位置，我们检查该位置是否已有元素。如果没有，我们直接将元素存入。
3. **冲突解决**：如果位置已被占用，我们检查当前位置的键是否与待插入元素的键相同。如果相同，我们覆盖原有元素；如果不同，我们处理哈希冲突。
4. **链表处理**：在处理哈希冲突时，如果元素以链表形式存储，我们把新元素添加到链表的尾部。
5. **树化操作**：如果链表长度超过8个元素，为了提高搜索效率，链表将被转换成红黑树。
6. **扩容判断**：最后，如果数组的总元素数量超过了数组长度 12 与负载因子（通常为 0.75，即 `12 * 0.75 = 9`）的乘积，即达到扩容阈值，哈希表将进行扩容操作。

> <center><img src="pic/img-15.png" width="960"/></center>

<center><font color=silver>img-1.4</font></center>

> get 查询流程

首先计算出 Hash 值，然后去数组查询（红黑树或者链表）

**7. 多线程环境怎么使用 Map 呢？ConcurrentHashMap 了解过吗？**

多线程环境可以使用 Collections.synchronizedMap 同步加锁的方式，还可以使用 HashTable，但是同步的方式显然性能不达标，而 ConurrentHashMap 更适合高并发场景使用。
ConcurrentHashmap 在 JDK1.7 和 1.8 的版本改动比较大，1.7 使用 Segment + HashEntry 分段锁的方式实现，1.8 则抛弃了 Segment，改为使用 CAS + synchronized + Node 实现，同样也加入了红黑树，避免链表过长导致性能的问题。

**8. 分段锁**

从结构上说，1.7 版本的 ConcurrentHashMap 采用分段锁机制，里面包含一个 Segment 数组，Segment 继承与 ReentrantLock，Segment 则包含 HashEntry 的数组，HashEntry 本身就是一个链表的结构，具有保存 key、value 的能力，以及能指向下一个节点的指针。
实际上就是相当于每个 Segment 都是一个 HashMap，默认的 Segment 长度是16，也就是支持 16 个线程的并发写，Segment 之间相互不会受到影响。

**1）put 流程**

1. 计算 Hash，定位到 Segment，Segment 如果是空就先初始化
2. 使用 ReentrantLock 加锁，如果获取锁失败则尝试自旋，自旋超过次数就阻塞获取，保证一定获取锁成功
3. 遍历 HashEntry，进行替换或者是插入操作

> <center><img src="pic/img-16.png" width="960"/></center>

<center><font color=silver>img-1.5</font></center>

**2）get 流程**

key通过 Hash 定位到 Segment，再遍历链表定位到具体的元素上，需要注意的是 value 是 Volatile 的，所以 get 不需要加锁。

**9. CAS + synchronzied**

1.8 抛弃分段锁，转为用 CAS + synchronized 来实现，同样 HashEntry 改为 Node，也加入了红黑树的实现。




## 一、数据库

### 1. MySQL高频面试题

#### 1.1 索引相关

**1. 什么是索引**

索引是一种数据结构，类似于书籍目录，可以帮助数据库快速定位和访问表中特定数据行。

**2. 索引是个什么样的数据结构呢?**

索引的数据结构和具体存储引擎的实现有关，在 MySQL 中使用较多的索引有 `Hash 索引`，`B+ 树索引` 等，而MySQL默认的 `InnoDB` 存储引擎的索引实现默认为：`B+ 树索引`。

**3. Hash 索引和 B+ 树索引有什么区别以及优劣势?**

> 首先要知道 Hash 索引和 B+ 树索引的底层实现原理：

- Hash 索引底层就是 Hash 表，进行查找时，调用一次 Hash 函数就可以获取到相应的键值，后进行回表查询获得实际数据。
- B+ 树底层实现是多路平衡查找树。对于每一次的查询都是从根节点出发，查找到叶子节点方可以获得所查键值，然后根据查询判断是否需要回表查询数据。

> 二者的不同之处：

- 因为在 Hash 索引中经过 Hash 函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。而 B+ 树的所有节点皆遵循`左节点 < 父节点 < 右节点`，天然支持范围查询。
- Hash 索引不支持使用索引进行排序，原理同上。
- Hash 索引不支持模糊查询以及多列索引的最左前缀匹配。原理也是因为hash函数的不可预测。
- Hash 索引任何时候都避免不了回表查询数据，而 B+ 树在符合某些条件（聚簇索引，覆盖索引等）的时候可以只通过索引完成查询。
- Hash 索引虽然在等值查询上较快，但是不稳定，性能不可预测，当某个键值存在大量重复的时候,发生 Hash 碰撞，此时效率可能极差。而 B+ 树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低。

**4. 什么是聚簇索引、覆盖索引?**

- **聚簇索引**：
  - **定义：**聚簇索引是一种数据存储方式，表中的数据行按索引的顺序实际存储在磁盘上。一个表只能有一个聚簇索引，因为数据行只能按一种顺序排列。
  - **特性：**
    - **数据存储顺序**：数据行的物理顺序与索引顺序一致。
    - **高效查询**：对索引键值的范围查询、排序查询性能较高，因为数据按索引顺序存储，减少了数据访问的随机性。
    - **主键作为聚簇索引**：通常情况下，主键会被设置为聚簇索引。如果没有主键，则挑选一个唯一键建立聚簇索引。如果没有唯一键，则隐式的生成一个键来建立聚簇索引。
    - **更新和插入**：插入和删除操作可能会导致数据的重新排列，从而影响性能。
    - **索引包含数据**：叶节点包含实际数据行，不需要二次查询。
  - **示例：**假设有一个表 `students`，包含 `student_id`（主键）和 `name` 列。如果 `student_id` 是聚簇索引，那么数据行会按 `student_id` 排序存储。
- **覆盖索引：**
  - **定义：**覆盖索引是指一个索引包含所有查询所需的字段，查询可以只通过索引获得所有需要的数据，而不需要访问数据行。
  - **特性：**
    - **减少I/O操作**：因为索引包含了所有查询需要的字段，查询可以完全从索引中获取数据，不需要再访问数据行，减少了I/O操作。
    - **提高查询性能**：在只需访问索引的情况下，查询性能大幅提高，特别是对于大表和复杂查询。
    - **多列索引**：通常通过多列联合索引实现，确保索引覆盖查询中的所有列。
  - **示例：**假设有一个表 `students`，包含 `student_id`、`name` 和 `age` 列。若有一个查询 `SELECT student_id, name FROM students WHERE age = 20`，并且有一个联合索引 `INDEX (age, student_id, name)`，则这个索引就是覆盖索引，因为它包含了查询所需的所有字段。

**5. 联合索引是什么?为什么需要注意联合索引中的顺序?**

MySQL可以使用多个字段建立联合索引。要命中联合索引，查询时必须按字段建立时的顺序使用这些字段。
原因是 MySQL 需要有序索引。例如，若有 `name, age, school` 的联合索引，索引先按 `name` 排序，`name` 相同时再按 `age` 排序，最后按 `school` 排序。因此，建立联合索引时，应将查询频繁或选择性高的列放在前面，也可以根据具体查询需求和表结构进行调整。

**6. 创建的索引有没有被使用到?或者说怎么才可以知道这条语句运行很慢的原因?**

MySQL提供了 `EXPLAIN` 命令来查看查询语句的执行计划。MySQL在执行语句前，会通过查询优化器分析该语句，生成执行计划，其中包含许多重要信息。通过这些信息，可以判断是否命中了索引。例如，`possible_keys`、`key` 和 `key_len` 字段分别表示可能使用的索引、实际使用的索引以及索引用的长度。

#### 1.2 事务相关

**1. 什么是事务?**

数据库的事务（Transaction）是一组逻辑操作单元，这些操作要么全部执行成功，要么全部回滚。

假设有一个银行转账的场景，从账户 A 转账 100 元到账户 B，这个操作可以分为以下几步：
- 检查账户A的余额是否足够。
- 从账户A扣除100元。
- 向账户B增加100元。

这几步操作必须作为一个事务处理，要么全部执行成功，要么全部失败回滚。如果在扣除账户A的100元后，系统发生故障，事务应该回滚，恢复账户A的100元。

**2. 同时有多个事务在进行会怎么样呢?**

- **脏读**：事务 A 读取到事务 B 未提交的数据，而事务 B 随后回滚了这些数据。
- **不可重复读**：事务 A 在同一事务内的两次查询结果可能会不同，因为在此期间事务 B 进行了提交操作。
- **幻读**：事务 A 读取了一个范围内的数据，同时事务 B 在此范围内插入了一条新数据，导致事务A产生“幻觉”，即在后续查询中看到额外的数据。

**3. 不可重复读和幻读的区别：**

- **不可重复读**：关注的是同一行数据在两次读取之间被修改。重点在于**修改**操作。
- **幻读**：关注的是查询结果集在两次读取之间因插入或删除数据而发生变化。重点在于**插入或删除**操作。

**4. MySQL的事务隔离级别了解吗? **

- **未提交读 (READ UNCOMMITTED)**：在这个隔离级别下，其他事务可以看到本事务未提交的修改，因此会出现脏读的问题（读取到其他事务未提交的数据，而这些数据可能会被回滚）。由于性能优势不明显且存在较多问题，这个级别很少使用。
- **已提交读 (READ COMMITTED)**：其他事务只能读取到本事务已经提交的数据。在这个隔离级别下，会出现不可重复读的问题，即同一事务内的两次读取结果可能不同，因为另一事务在中间修改了数据。
- **可重复读 (REPEATABLE READ)**：可重复读隔离级别解决了不可重复读的问题，但仍然可能出现幻读。当读取 id > 10 的数据行时，会对所有涉及的行加上读锁。但如果另一个事务在此期间插入了一条id=11的数据，由于新插入的数据不受之前锁的影响，下一次查询会发现多了一条id=11的数据，而上次查询没有获取到。这可能导致主键冲突的问题。
- **可串行化 (SERIALIZABLE)**：这是最高的隔离级别，可以解决所有问题，因为它强制将所有操作串行执行。然而，这会导致并发性能显著下降，因此也很少使用。

**5. InnoDB 使用的是哪种隔离级别呢?**

InnoDB 默认使用的是可重复读隔离级别。

**6. 对 MySQL 的锁了解吗?**

- **锁的类型**
  - **全局锁**：锁住整个数据库实例，通常用于备份和恢复操作。执行 `FLUSH TABLES WITH READ LOCK` 命令会加上全局锁。
  - **表级锁**：锁住整个表，分为读锁和写锁。
    - **读锁（共享锁）**：多个事务可以同时读，但不能写。
      - **写锁（排他锁）**：其他事务既不能读也不能写。
- **锁的存储引擎**
  - **InnoDB存储引擎**：
    - 默认使用行级锁。
    - 支持自动死锁检测和自动回滚。
    - 支持外键和事务。
  - **MyISAM存储引擎**：
    - 只支持表级锁。
    - 适用于读多写少的应用场景。
- **死锁**：当两个或多个事务`互相等待`对方持有的锁时，便会产生死锁。InnoDB 引擎能够自动检测并处理死锁，通过回滚其中一个事务来解决。

**7. 事务的分类**

事务事务可以分为很多中类型，一般分为：**扁平事务、带有保存点的扁平事务、链事务、嵌套事务、分布式事务**。

> 扁平事务

扁平事务是事务管理中的基础形式，广泛应用于实际开发。它以单一层次执行所有操作，其主要缺点是不能提交或回滚事务的某一部分，或者分几个独立的步骤去提交。

```mysql
/*
BEGIN WORK
Operation 1
Operation 2
Operation 3
...
Operation N
COMMIT WORK
*/

# 举例
BEGIN WORK;

SELECT * FROM tale_name;

UPDATE table_name SET field1 = "xxx" WHERE field2 = 1;

COMMIT WORK;
```

> 带有保存点的扁平事务

**带有保存点的扁平事务**，不仅包含扁平事务的功能，还增加了回滚至事务早期状态的能力。当事务执行中出现错误，并非所有操作都需废弃，完全回滚可能代价过高。为此，引入了保存点机制，它允许系统记录事务的特定状态，以便在出错时能够回退到该点，从而优化资源利用并减少不必要的开销。

```mysql
BEGIN WORK;

SELECT * FROM tale_name;

SAVEPOINT t1;  # 建立保存点 t1

UPDATE table_name SET field1 = "xxx" WHERE field2 = 1;

SAVEPOINT t2;  # 建立保存点 t2

COMMIT WORK;

# 通过 ROLLBACK TO SAPOINT t1, 就可以返回保存点 t1
```

> 链事务

链事务是一种高效的事务处理方式，它在提交当前事务时，自动释放非必需的数据对象，并将必要的处理上下文无缝传递给紧随其后的事务。这种设计确保了事务操作的连续性，使得后继事务能够即时访问到前一个事务的结果，实现了操作的原子性。
与扁平事务相比，链事务在回滚机制上有所限制，仅能恢复到最近的一个保存点。而扁平事务则更为灵活，允许回滚至任意一个有效的保存点，从而提供了更细致的错误恢复能力。**并且，**链事务在执行 commit 后就会释放当前事务所持有的所有锁，而带有保存点的扁平事务不会影响所持有的锁。

```mysql
BEGIN WORK;

SELECT * FROM tale_name;

SAVEPOINT t1;  # 建立保存点 t1

UPDATE table_name SET field1 = "xxx" WHERE field2 = 1;

SAVEPOINT t2;  # 建立保存点 t2

COMMIT WORK;

# 不能直接 ROLLBACK 到保存点 t1，只能恢复到最近的保存点 t2
```

> 嵌套事务

事务嵌套结构类似于横向树形结构，顶层事务作为根节点，控制整个事务流程。每个事务都可能有一个父事务，而其下一层则构成子事务。 
子事务具有独立性，既可以提交也可以回滚。然而，子事务的提交并不立即生效，必须等待其父事务的提交。这意味着所有子事务的最终提交状态依赖于顶层事务的提交。此外，如果任何一个事务发生回滚，其所有子事务也将随之回滚，确保了事务的一致性和完整性。 这种嵌套事务模式强化了事务的层级关系，使得事务管理更加有序和可控。

```mysql
BEGIN WORK;
	SubTransaction1:
		BEGIN WORK;
			SubOperation1;
		COMMIT WORK;
	SubTransaction2:
		BEGIN WORK;
			SubOperation2;
		COMMIT WORK;
	...
	SubTransactionN:
		BEGIN WORK;
			SubOperationN;
		COMMIT WORK;
```

> 分布式事务

分布式事务是在多个物理位置运行的事务，它们通过网络在分布式系统中的不同节点上执行。这种事务类型要求跨网络对数据进行协调和访问，以确保事务的一致性、原子性、隔离性和持久性（ACID属性）。
简单来说，分布式事务涉及在不同地理位置的多个系统或服务之间进行数据操作，这些操作需要通过网络通信来同步，以保证整个事务的完整性和正确性。

#### 1.3 存储引擎相关

**1. 什么是存储引擎?**

存储引擎是如何存储数据、如何为存储的数据建立索引和如何更新、查询数据等技术的`实现方法`。因为在关系数据库中数据的存储是以表的形式存储的，所以存储引擎也可以称为表类型。

**2. MySQL 常见的三种数据库存储引擎分别是？**

- **InnoDB 存储引擎**
  - **事务支持：**支持事务（ACID兼容，原子性-Atomicity、一致性-Consistency、隔离性-Isolation、持久性-Durability），具有提交、回滚和崩溃恢复能力。
  - **锁机制**：行级锁定和非锁定读，适用于多用户部署。
  - **外键支持**：唯一支持外键完整性约束的引擎。
  - **自动增长列**：自动增长列必须是索引，支持手动插入和起始值设置。
  - **存储结构**：数据和索引存储在逻辑表空间中，支持大表。
  - **缓冲池**：自带缓冲池用于缓存数据和索引。
  - **表数据**：按主键顺序存放，支持大文件和大表。

- **MyISAM 存储引擎**
  - **事务支持**：不支持事务，不支持外键。
  - **性能**：插入和查询速度较快。
  - **锁机制**：表级锁定。
  - **索引支持**：每个表最多 64 个索引，最大键长度 1000 字节，支持 BLOB 和 TEXT 列索引。
  - **自动增长列**：支持自动增长列，更新速度比 InnoDB 快。
  - **存储格式**：支持静态表、动态表和压缩表，静态表故障恢复简单，动态表节省空间但需定期优化。
  - **数据文件**：生成三个文件（.frm、.MYD、.MYI），数据和索引文件可放置在不同目录。

- **MEMORY 存储引擎**
  - **数据存储**：数据存储在内存中，访问速度快，但数据不持久。
  - **索引支持**：每个表最多 32 个索引，最大键长度 500 字节，支持 AUTO_INCREMENT 列和 NULL 值索引。
  - **默认索引**：默认使用 Hash 索引，适合相等比较，支持 Btree 索引用于范围比较。
  - **数据类型**：固定长度格式，不支持 BLOB 和 TEXT 类型。
  - **表文件**：每个表对应一个.frm 文件，服务器关闭后数据丢失但表结构存在。
  - **内存限制**：受 `max_heap_table_size` 系统变量限制，创建时可指定最大行数。

- **总结&对比**
  - **InnoDB**：适用于需要事务支持和数据完整性的场景，支持复杂查询和多用户并发。
  - **MyISAM**：适用于读多写少的应用场景，如 Web 和数据仓储，插入和查询性能优越。
  - **MEMORY**：适用于需要高速读写操作的场景，如临时数据存储和会话管理，数据不持久。

<table>
    <th colspan = "4">储存引擎的对比</th>
    <tr>
        <td>名称</td>
        <td>InnoDB</td>
        <td>MyISAM</td>
        <td>MEMORY</td>
    </tr>
    <tr>
        <td>事务安全</td>
        <td>支持</td>
        <td>无</td>
        <td>无</td>
    </tr>
    <tr>
        <td>空间使用</td>
        <td>高</td>
        <td>低</td>
        <td>低</td>
    </tr>
    <tr>
        <td>内存使用</td>
        <td>高</td>
        <td>低</td>
        <td>低</td>
    </tr>
    <tr>
        <td>插入数据的速度</td>
        <td>低</td>
        <td>高</td>
        <td>高</td>
    </tr>
    <tr>
        <td>对外键的支持</td>
        <td>支持</td>
        <td>无</td>
        <td>无</td>
    </tr>
</table>

#### 1.3 零散问题

**1. MySQL 中的 varchar 和 char 有什么区别？**
char 是`定长字段`，例如申明 char(10)，无论实际存储内容多少，该字段始终占用 10 个字符的存储空间。而 varchar 是`变长字段`，只占用实际存储内容的空间加上一个字节的额外存储空间。
从检索效率角度看，char 的效率通常高于 varchar。因此，在选择字段类型时，如果能确定字段值的固定长度，可以使用 char；如果长度不确定，建议使用 varchar。

**2. 超大分页怎么处理？**

- **数据库层面：**主要是减少不必要的数据加载，例如：

  ```mysql
  select * from table where age > 20 limit 1000000,10
  # 可以改进以下形式，虽然同样同样大小的数据，当所需字段都在索引中，查询速度更快
  select * from table where id in (select id from table where age > 20 limit 1000000,10)
  # 如果 id 是连续的，可以采用
  select * from table where id > 1000000 limit 10
  ```

- **从需求层面：**避免类似直接跳转到数百万页之后的某一页的需求，而是采用逐页查看或者按给定路线查看的方式，这样更可预测和易于缓存。

针对超大分页的解决方案主要`依赖缓存`，通过预测性地将内容缓存到像 Redis 这样的键值数据库中，可以直接返回用户请求，从而提高查询效率。

**3. 说一说三个范式**

- **第一范式：**确保每列都是原子的，不可再分。
- **第二范式：**确保表中的每列都和主键相关，而不是部分相关。
- **第三范式：**确保表中的每列只和主键相关，而不是与其它非主键列相关。

<br>

### 2. MySQL 优化方案

> 在开始介绍如何优化 SQL 之前，先附上 MySQL 内部逻辑图。

> <center><img src="pic/img-01.png" width="960"/></center>

<center><font color=silver>img-1.1</font></center>

**① 连接器：**主要负责跟客户端建立连接、获取权限、维持和管理连接

**② 查询缓存：**优先从缓存中查询数据，若缓存中有结果则直接返回；否则，再从数据库查询。
MySQL 缓存是默认关闭的，在 MySQL 8.0 中已移除该功能，主要因为其使用场景受限：
- 缓存的存储格式为键值对（key: SQL 语句，value: 数据值），SQL 语句若有任何不同都会导致直接数据库查询；
- 由于数据经常变化，相关缓存数据需在数据库更新时移除。

**③ 解析器/分析器**：负责对 SQL 语句进行词法和语法解析，生成抽象语法树，并使用预处理器进行语义校验，确保表和字段存在。

**④ 优化器：**将经过词法和语法解析后的语法树，通过数据字典和统计信息，经过运算得出执行计划，包括选择使用哪个索引

**⑤ 执行器：**根据执行计划，调用存储引擎提供的 API 接口，完成 SQL 的执行。

> SQL 语句及索引的优化

**1. 避免使用子查询**

```mysql
# 低效
SELECT * FROM t1 WHERE id IN (SELECT id FROM t2 WHERE name = 'tang');

# 优化
SELECT t1.* FROM t1 JOIN t2 ON t1.id = t2.id;
```

由于MySQL优化器对子查询处理能力较弱，建议改写成 Inner Join，这样 MySQL 不需在内存中创建临时表，效率更高。但需注意：这种优化仅对 SELECT 有效，对 UPDATE/DELETE 中的子查询无效，因此在生产环境中应尽量避免使用子查询。

**2. 用 IN 替换 OR**

```mysql
# 低效
SELECT * FROM t WHERE id = 10 OR id = 20 OR id = 30;

# 高效
SELECT * FROM t WHERE id IN (10, 20, 30);
```

MySQL 对 IN 进行了优化，将 IN 中的常量存储在一个已排序的数组中。但如果数值较多，消耗也会增大。例如，对于连续数值，使用 BETWEEN 代替 IN；或使用连接替换。

**3. 读取适当记录 LIMIT M,N**

```mysql
# 低效
SELECT id, name FROM t LIMIT 866613, 20;

# 优化
SELECT id, name FORM table_name WHERE id > 866613 LIMIT 20;
```

随着表数据量增加，LIMIT 分页查询会变慢。MySQL 并非跳过 OFFSET 行，而是取 OFFSET+N行，放弃前 OFFSET 行，返回 N 行。OFFSET 越大，效率越低。可以采取——先取前一页最大行的 ID，然后通过该 ID 限制下一页起点。

**4. 禁止不必要的 Order By 排序**

```mysql
# 低效
SELECT goods_id, count(*) FROM t GROUP BY goods_id;

# 高效
SELECT goods_id, count(*) FROM t GROUP BY goods_id ORDER BY NULL;
```

如果对结果没有排序要求，尽量少用排序；如果排序字段未使用索引，也应少用排序；分组统计查询时可以禁止默认排序。

**5. 总和查询可使用UNION ALL**

UNION 需要合并结果集并进行唯一性过滤，增加 CPU 运算和资源消耗。而 UNION ALL 则不进行唯一性过滤，适用于没有重复数据的情况，提高速度。

**6. 避免随机取记录**

```mysql
SELECT * FROM t1 WHERE 1 = 1 ORDER BY RAND() LIMIT 4;
SELECT * FROM t1 WHERE id >= CEIL(RAND() * 1000) LIMIT 4;
```

以上语句无法使用索引。

**7. 将多次插入改为批量Insert**

```mysql
# 低效
INSERT INTO t(id, name) VALUES (1, 'aaa');
INSERT INTO t(id, name) VALUES (2, 'bbb');
INSERT INTO t(id, name) VALUES (3, 'ccc');

# 高效
INSERT INTO t(id, name) VALUES (1, 'aaa'), (2, 'bbb'), (3, 'ccc');
```

**8. 只返回必要列，避免使用 SELECT * **

使用具体字段列表代替`SELECT *`，以减少不必要的消耗，增加使用覆盖索引的可能性，并减少表结构变化带来的影响。

**9. 区分 IN 和 EXISTS**

`IN`（先执行子查询）适合外表大而内表小的情况；`EXISTS` （先访问外层表）适合外表小而内表大的情况。`IN` 可能返回错误结果，建议在确定且有限的集合时使用。

**10. 优化 Group By 语句**

```mysql
# 低效
SELECT job, AVG(sal) FROM emp GROUP BY job HAVING job = 'PRESIDENT' OR job = 'MANAGER'

# 高效
SELECT job, AVG(sal) FROM emp WHERE job = 'PRESIDENT' OR job = 'MANAGER' GROUP BY job;
```

- 如果对 Group By 结果没有排序要求，使用`ORDER BY NULL`；
- 尽量让 Group By 过程使用表的索引；
- 通过调大 `tmp_table_size` 参数，避免使用磁盘临时表；
- 使用 `SQL_BIG_RESULT` 提示优化器直接使用排序算法；
- 避免使用HAVING子句，改用WHERE子句提前过滤数据。

**11. 尽量使用数字型字段**

数值型字段的查询和连接性能优于字符型字段，避免逐个字符比较。

**12. 优化Join语句**

- 执行 Join 时，两个表的数据逐条比较会很慢。可以调整 Join Buffer 大小，提高性能。
- 在连接查询没有 WHERE 条件时，左连接的左表为驱动表，右连接的右表为驱动表，INNER JOIN 自动选择数据少的表为驱动表。存在WHERE条件时，带条件的表为驱动表。
- 驱动表和被驱动表的数据量、索引、Join Buffer Size 等都会影响 Join 语句的性能。尽量减少 Join 语句中的Nested Loop 次数，用小结果集驱动大结果集，优先优化 Nested Loop 的内层循环，对被驱动表的 Join 字段建立索引，避免左连接时的性能问题，适当添加冗余信息。

**13. 索引优化**

- 遵守最佳左前缀法则，不在索引列上进行计算或函数操作，避免索引失效。
- MySQL 8.0 开始支持函数索引。
- 避免类型转换导致索引失效，存储引擎不能使用索引中范围条件右边的列。
- 尽量使用覆盖索引，减少 select *，负向查询条件和 NULL 判断可能导致索引失效。
- LIKE 通配符使用时避免以 % 开头。
- 尽量减少 OR 条件，确保索引有效，区分度高的索引放在前面。
- 使用前缀索引减少索引长度。EXPLAIN 中的 type 至少要达到 range 级别，最好是 consts。

<br>

### 3. MySQL的又一神器-锁

#### 3.1 什么是锁

**1. 锁的概述**

在 MySQL 中，锁是一个重要的特性。数据库使用锁来支持并发访问共享资源，确保数据的完整性和一致性，从而在高并发情况下保证数据的正确性。

**2. 锁的两个概念**

在数据库中，锁（lock）和闩锁（latch）都有锁的含义，但它们的用途和特性不同。

- **Latch（闩锁）**：是一种轻量级锁，要求锁定时间非常短。如果锁定时间过长，会显著影响应用性能。在InnoDB 引擎中，Latch 分为互斥量（mutex）和读写锁（rwlock），用于确保并发线程操作临界资源的正确性，通常没有死锁检测机制。
- **Lock（锁）**：与事务相关，用于锁定数据库对象（如表、页、行）。Lock 通常在事务提交（commit）或回滚（rollback）后释放，不同事务隔离级别可能影响释放时间。

#### 3.2 InnoDB 存储引擎中的锁

**1. 锁的粒度**

在数据库中，锁的粒度可以分为表锁、页锁和行锁。这些锁的粒度可以升级，例如将多个行锁升级为一个页锁，或将页锁升级为表锁。

- **表锁**：表锁是 MySQL 存储引擎中粒度最大的锁，逻辑简单，系统负面影响小，获取和释放速度快，避免了死锁问题。然而，锁定整个表会导致资源争用，降低并发度。表锁主要用于 MyISAM、MEMORY、CSV 等非事务性存储引擎。
  
  > 特点：开销小、加锁快、不出现死锁、锁定粒度大、锁冲突概率高、并发度低。
  
- **页锁**：页锁是 MySQL 中的一种独特锁定级别，锁定粒度介于表锁和行锁之间，资源开销和并发能力也介于两者之间。页锁和行锁一样会发生死锁，主要用于 BerkeleyDB 存储引擎。

  > 特点：开销和加锁时间介于表锁和行锁之间、会出现死锁、锁定粒度适中、并发度一般。

- **行锁**：行锁锁定对象粒度最小，资源争用概率最低，提供最大的并发处理能力，但开销大、加锁慢，最容易发生死锁。

  > 开销大、加锁慢、会出现死锁、锁定粒度最小、锁冲突概率最低、并发度最高。

**2. 锁的类型**

> 数据操作主要有两种：读和写。数据库对这两种操作使用不同的锁；InnoDB 实现了标准的行级锁，即共享锁（Shared Lock, S Lock）和排他锁（Exclusive Lock, X Lock）。

- **共享锁（读锁，S Lock）**：允许事务读取一行数据。
- **排他锁（写锁，X Lock）**：允许事务删除或更新一行数据。

> 为了允许行锁和表锁共存，InnoDB 支持一种额外的锁机制——意向锁。意向锁是表级锁，用于实现多粒度锁机制，分为以下两种：

- **意向共享锁（IS Lock）**：表示事务想要获取一张表中某几行的共享锁。
- **意向排他锁（IX Lock）**：表示事务想要获取一张表中某几行的排他锁。

这些锁之间并非总是兼容的。有些锁之间存在冲突。例如，事务A获取某行某种锁后，事务B尝试获取同一行上的某种锁。如果B能够立即获取锁，则称为锁兼容；否则称为冲突。

| 锁类型的兼容性 |  IS 锁   |  IX 锁   |   S 锁   |   X 锁   |
| :------------: | :------: | :------: | :------: | :------: |
|     IS 锁      | &#10004; | &#10004; | &#10004; | &#10006; |
|     IX 锁      | &#10004; | &#10004; | &#10006; | &#10006; |
|      S 锁      | &#10004; | &#10006; | &#10004; | &#10006; |
|      X 锁      | &#10006; | &#10006; | &#10006; | &#10006; |

**4. 一致性锁定读和一致性非锁定读**

> 一致性锁定读 (Locking Reads)
> 在事务中执行查询时，普通的 `SELECT` 语句不会对数据加锁，其他事务仍可以更新和删除这些数据。为提供更高的安全性，InnoDB 提供了两种锁定读：

- `SELECT ... LOCK IN SHARE MODE`：对读取的行加 S 锁，其他事务可以对这些行加 S 锁，但加 X 锁会被阻塞。
- `SELECT ... FOR UPDATE`：对查询的行及相关索引记录加 X 锁，其他事务的 S 锁或 X 锁请求都会被阻塞。这些锁在事务提交或回滚后释放。注意，只有在禁用自动提交时，`SELECT FOR UPDATE` 才能锁定行；若开启自动提交，匹配的行不会被锁定。

> 一致性非锁定读 (Consistent Nonlocking Read)
> 一致性非锁定读是指 InnoDB 存储引擎通过多版本控制（MVCC）读取行数据。如果行正在执行 `DELETE` 或 `UPDATE` 操作，读取操作不会等待行锁的释放，而是读取行的一个快照。这种机制显著提高了数据库的并发性。
> 一致性非锁定读是InnoDB的默认读取方式，即读取操作不会占用和等待行上的锁。在事务隔离级别 `READ COMMITTED` 和 `REPEATABLE READ` 下，InnoDB 使用一致性非锁定读。

- `READ COMMITTED` 隔离级别：读取最新的快照数据。
- `REPEATABLE READ` 隔离级别：读取事务开始时的行数据版本。

**5. 行锁的算法**

InnoDB存储引擎有3种行锁的算法，其分别是：

- Record Lock：单个行记录上的锁。
- Gap Lock：间隙锁，锁定一个范围，但不包含记录本身。
- Next-Key Lock：锁定一个范围，并且锁定记录本身。

**Record Lock**：总是会去锁住索引记录，如果 InnoDB 存储引擎表在建立的时候没有设置任何一个索引，那么这时 InnoDB 存储引擎会使用隐式的主键来进行锁定。

**Gap Lock的作用**：是为了阻止多个事务将记录插入到同一个范围内，设计它的目的是用来解决 **Phontom Problem（幻读问题）**。在 MySQL 默认的隔离级别（Repeatable Read）下，InnoDB 就是使用它来解决幻读问题。

**Next-Key Lock**：结合了 Gap Lock 和 Record Lock 的一种锁定算法，在 Next-Key Lock 算法下，InnoDB 对于行的查询都是采用这种锁定算法。除了Next-Key Locking，还有 **Previous-Key Locking** 技术，这种技术跟 Next-Key Lock 正好相反，锁定的区间是区间范围和前一个值。举个例子10，20，30，那么这两种索引的锁定区间为：

> <center><img src="pic/img-02.png" width="960"/></center>

<center><font color=silver>img-1.2</font></center>

#### 3.3 锁带来的问题

|                      |     脏读     |  不可重复读  |     幻读     |
| :------------------: | :----------: | :----------: | :----------: |
| **READ UNCOMMITTED** | **&#10004;** | **&#10004;** | **&#10004;** |
|  **READ COMMITTED**  | **&#10006;** | **&#10004;** | **&#10004;** |
| **REPEATABEL READ**  | **&#10006;** | **&#10006;** | **&#10006;** |
|   **SERIALIZABLE**   |   &#10006;   |   &#10006;   |   &#10006;   |

<br>

<br>

## 二、系统设计

### 1. 前后端分离概述

#### 1.1 前后端分离和 SPA

前后端分离的典型例子是单页应用（SPA，Single-page Application），它通过异步接口（AJAX/JSONP）从后端获取数据，前端只负责展示。然而，这种方法存在两个问题：

1. **应用范围受限**：在 Web 服务中，SPA 所占比例较少。很多场景下，需要同步或同步 + 异步的混合模式，SPA 无法作为通用解决方案。
2. **职责不清**：现阶段的 SPA 开发中，接口通常按照展现逻辑提供，同时为了提高效率，后端也参与了视图层的工作，这不是真正的前后端分离。

为了真正实现前后端分离，应从`职责`上进行划分：

> - **前端**：负责 View 和 Controller 层。
> - **后端**：只负责 Model 层，处理业务和数据持久化。

#### 1.2 Node.js 的作用

**1. Node.js 的研发背景：**在前后端完全分离的时代，前端的职责扩展到 Controller 层。然而，前后端在职责和技术上的差异可能导致以下问题：

- **技术隔阂**：后端开发人员不熟悉前端 HTML 结构，前端开发人员不了解后端代码。
- **开发效率**：前端需要快速上手，而 Node.js 的出现解决了这些问题。Node.js 适合高并发、I/O 密集、少量业务逻辑的场景，前端开发人员可以快速掌握。

**2. Node.js 的工作流程**

1. 浏览器请求 Node.js 服务器。
2. Node.js 服务器请求后端 JSP 接口。
3. JSP 接口返回 JSON 数据给 Node.js。
4. Node.js 将 JSON 数据渲染为 HTML 页面。
5. Node.js 将 HTML 页面发送给浏览器。

**3. Node.js 作为中间层的好处**

- **适配性提升：**Node.js 中间层可以为 PC 端、移动端和 APP 端提供统一的接口，简化前端与后端的交互，减少沟通成本。
- **响应速度提升**：Node.js 可以在中间层处理部分逻辑，减轻前端和后端的负担，提高响应速度。
- **性能提升**：Node.js 中间层可以将多个后端接口的数据在内网阶段拼装好，减少前端请求次数，提高性能。
- **异步与模板统一**：Node.js 支持异步操作，前端模板可以在不同条件下使用不同渲染方式，提高页面渲染效率。

<br>

### 2. 前后端分离之 JWT 用户认证

> 在前后端分离开发中，用户认证至关重要。由于 HTTP 协议是无状态的，每次请求时，服务器无法记住先前的认证状态。为了确保系统安全，必须在每次请求中验证用户的登录状态。

**1. 传统方式**

在传统的前后端分离模式中，通过 Restful API 进行数据交互，通常采用以下方式进行用户认证：

1. **前端登录**：用户通过前端输入账号和密码进行登录。
2. **生成Token**：后端根据用户信息生成一个 Token，并将其与用户 ID 一起存储在数据库或 Session 中。
3. **传递Token**：后端将生成的 Token 传递给前端，前端将 Token 存储在浏览器的 Cookie 中。
4. **请求验证**：浏览器在每次请求时携带 Cookie，后端根据 Cookie 中的 Token 查询用户，验证其登录状态。

这种方法存在诸多问题，例如 `XSS漏洞` 可能导致 Token 泄露。虽然可以通过设置 `httpOnly` 和 `secure` 属性来保护 Cookie，但这并不能完全防止跨站请求伪造（XSRF）攻击。此外，存储在数据库中的验证信息每次都需要查询，增加了服务器的开销。

**2. Json Web Token（JWT）**

JWT 是一种开放标准（RFC 7519），用于在通信双方之间以 JSON 对象的形式安全传递信息。JWT 具有简洁（Compact）和自包含（Self-contained）的特点：

- **简洁**：可以通过 URL、POST 参数或 HTTP 头部传递，数据量小，传输速度快。
- **自包含**：负载中包含了所有需要的信息，避免了多次查询数据库。

**3. JWT 的使用**

1. **用户登录**：前端通过 Web 表单将用户名和密码发送到后端（建议使用 HTTPS）。
2. **生成 JWT**：后端验证成功后，生成包含用户信息的 JWT，并将其返回给前端。
3. **存储 JWT**：前端将 JWT 存储在 localStorage 或 sessionStorage 中。
4. **请求时携带 JWT**：前端在每次请求时将 JWT 放入 HTTP 头部的 Authorization 字段中。
5. **验证 JWT**：后端检查 JWT 的有效性，包括签名是否正确、Token 是否过期等。
6. **处理请求**：验证通过后，后端使用 JWT 中的信息进行处理，并返回结果。

**4. 比较和总结**

相比传统的 Session 方式，JWT 将用户状态分散到客户端，减轻了服务器的存储压力。虽然 JWT 会增加服务器的计算压力，但在很多场景下，这种压力是可以接受的。JWT 特别适用于需要传递非敏感信息的场景，如用户 ID 等。
对于大型应用，使用 JWT 可以避免 Session 同步的复杂性，特别是在多服务器和多子域名的情况下。JWT 还可以用于实现单点登录（SSO）。
最后，JWT 不应包含敏感信息，如用户密码，应仅用于传递非敏感信息，以确保安全性。

|          | Session                                                      | JWT                                                          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 存储状态 | Session 会话信息存储在服务器                                 | JWT 令牌存储在客户端                                         |
| 扩展性   | Seesion 需要服务器在内存或数据库中保存会话信息，当用户数量增多时，需要更多的存储资源。 | JWT 令牌包含了用户信息和声明，服务器可以避免频繁访问存储，使得系统更容易扩展。 |
| 状态性   | Session 依赖服务器的状态来验证用户身份，需要在服务器端保存会话状态。 | JWT 是无状态的，服务器可以直接解密和验证令牌，无需保存任何状态信息。 |
| 跨域通信 | Session 则需要处理跨域通信的问题                             | JWT 存储在客户端，可以轻松地在不同域名的服务器之间传递       |
| 时效性   | Session 的有效期由服务器控制，可以设置较短的时间以提高安全性，但可能导致用户需要频繁重新登录。 | JWT 可以包含令牌的过期时间，客户端可据此判断是否需要刷新令牌。 |

<br>

### 3. 单点登录机制原理

#### 3.1 单系统登录机制

**1. http 无状态协议**

Web 应用采用 `browser/server` 架构，http 作为通信协议。http 是无状态协议，浏览器的每一次请求，服务器会独立处理，不与之前或之后的请求产生关联，访问服务器资源虽然方便，但也带来了安全风险。为了保护敏感数据，我们需要对浏览器的访问请求进行限制。这就需要服务器识别并响应合法请求，同时忽略非法请求。由于HTTP协议本身是无状态的，因此需要服务器和浏览器共同维护一个会话状态，这就是会话机制的作用。

**2. 会话机制**

浏览器首次向服务器发起请求时，服务器会创建一个会话，并生成一个唯一的会话 ID。这个 ID 随后作为响应的一部分发送回浏览器。浏览器接收到 ID 后，将其存储起来。在随后的请求中，浏览器会在请求头中携带这个会话 ID。服务器通过检查请求中的会话 ID，就能识别出请求是否来自同一个用户，从而建立起请求之间的关联。

**3. 登录状态**

通过会话机制，我们可以清晰地管理用户的登录状态。设想浏览器首次向服务器发起请求时，需要提供用户名和密码以验证身份。服务器接收到这些凭据后，会与数据库中的记录进行比对。如果验证成功，服务器便确认当前会话的用户是合法的，并应该将该会话标记为“已授权”或“已登录”。这种状态信息自然需要存储在`会话对象`中。Tomcat 服务器在会话对象中设置登录状态的方式如下：

```java
HttpSession session = request.getSession();
// 在会话对象中添加标识，表示用户是否已经通过身份验证
session.setAttribute("isLogin", true);

// 服务器在用户进行后续请求时，通过会话对象快速识别其登录状态，从而提供相应的服务和权限
HttpSession session = request.getSession();
session.getAttribute("isLogin");
```

#### 3.2 多系统的复杂性

随着 Web 系统的发展，我们从单一的系统演变为由多个子系统组成的复杂应用群。用户在使用这些系统时，不应该面临重复登录和注销的繁琐过程。系统的复杂性应该由系统内部处理，而不是转嫁给用户。用户应该能够像访问单一系统一样，仅需一次登录和注销，就能便捷地使用整个Web应用群。

单系统登录解决方案虽然在单一系统中运行良好，但在多系统组成的应用群中却显得力不从心。原因如下：

1. **Cookie 的域限制**：Cookie 的有效范围受限于其设置的域。浏览器只会发送与请求域名匹配的 Cookie，这意味着不同域的系统无法通过 Cookie 共享会话状态。
2. **域名统一的挑战**：即使将所有子系统放在一个顶级域名下，如 "*.baidu.com"，并将 Cookie 的域设置为 "baidu.com"，这种做法在理论上可行，但在实践中存在诸多限制。应用群的域名需要统一管理，这在大型组织或使用不同子域的系统中可能难以实现。
3. **技术栈的多样性**：不同子系统可能使用不同的技术栈，例如 Java、PHP、.NET 等。这些系统可能使用不同的会话管理机制和 Cookie key 值，导致共享 Cookie 的方式无法跨技术平台工作。
4. **安全性问题**：Cookie存储在用户浏览器上，容易受到跨站脚本（XSS）和跨站请求伪造（CSRF）等攻击，存在安全隐患。

鉴于这些限制，单点登录（SSO）成为了解决多系统应用群登录问题的理想方案。SSO允许用户只需登录一次，即可访问所有相关联的系统，而无需重复认证。

#### 3.3 单点登录

单点登录（Single Sign-On，简称SSO）是一种身份验证机制，它允许用户在多个系统组成的应用群中，只需登录一次即可访问所有系统，而无需重复登录。SSO 包括单点登录和单点注销两个主要部分。

**1. 登录**

当用户首次登录时，认证中心会验证其凭据。一旦验证通过，认证中心将创建一个授权令牌并发送给用户。这个令牌随后作为参数在用户访问其他子系统时传递。子系统接收到令牌后，会与认证中心通信以验证令牌的有效性。验证成功后，子系统便可以基于这个令牌为用户创建局部会话，允许用户访问系统资源，而这个过程对用户来说是透明的。

> <center><img src="pic/img-03.png" width="960"/></center>

<center><font color=silver>img-2.1</font></center>

对上图的简要阐述：

| 步骤       | 描述                                                         |
| ---------- | ------------------------------------------------------------ |
| 1.  ~  3.  | 用户访问系统 1 的受保护资源，系统 1 发现用户未登录，跳转至 SSO 认证中心，并将自己的地址作为参数； |
| 4.      5. | SSO 认证中心发现用户未登录，将用户引导至登录页面；           |
| 6.         | 用户输入用户名密码提交登录申请；                             |
| 7.  ~  9.  | SSO 认证中心校验用户信息，创建用户与 SSO 认证中心之间的会话，称为全局会话，同时创建授权令牌； |
| 10.        | SSO 认证中心带着令牌跳转会最初的请求地址（系统1）；          |
| 11.        | 系统 1 拿到令牌，去 SSO 认证中心校验令牌是否有效；           |
| 12. ~ 14.  | SSO 认证中心校验令牌，返回有效，注册系统 1；                 |
| 15.    16. | 系统 1 使用该令牌创建与用户的会话，称为局部会话，返回受保护资源； |
| 17.        | 用户访问系统 2 的受保护资源；                                |
| 18.   19.  | 系统 2 发现用户未登录，跳转至 SSO 认证中心，并将自己的地址作为参数； |
| 20.   21.  | 认证中心发现用户已登录，跳转回系统 2 的地址，并附上令牌；    |
| 22.        | 系统2拿到令牌，去 SSO 认证中心校验令牌是否有效；             |
| 23. ~ 25.  | SSO 认证中心校验令牌，返回有效，注册系统 2；                 |
| 26.   27.  | 系统 2 使用该令牌创建与用户的局部会话，返回受保护资源。      |

用户登录成功之后，会与sso认证中心及各个子系统建立会话

- 用户与sso认证中心建立的会话称为全局会话
- 用户与各个子系统建立的会话称为局部会话，局部会话建立之后，用户访问子系统受保护资源将不再通过 SSO 认证中心

> 全局会话与局部会话有如下约束关系：

- 局部会话存在，全局会话一定存在；
- 全局会话存在，局部会话不一定存在；
- 全局会话销毁，局部会话必须销毁。

**2. 注销**

单点登录自然也要单点注销，在一个子系统中注销，所有子系统的会话都将被销毁，用下面的图来说明

> <center><img src="pic/img-04.png" width="960"/></center>

<center><font color=silver>img-2.2</font></center>

SSO 认证中心一直监听全局会话的状态，一旦全局会话销毁，监听器将通知所有注册系统执行注销操作。
下面对上图简要说明：

| 步骤     | 描述                                                         |
| -------- | ------------------------------------------------------------ |
| 1.       | 用户向系统 1 发起注销请求；                                  |
| 2.    3. | 系统 1 根据用户与系统 1 建立的会话 id 拿到令牌，向 SSO 认证中心发起注销请求； |
| 4. ~ 6.  | SSO 认证中心校验令牌有效，销毁全局会话，同时取出所有用此令牌注册的系统地址； |
| 7. ~ 9.  | SSO 认证中心向所有注册系统发起注销请求，各注册系统接收 SSO 认证中心的注销请求，销毁局部会话； |
| 10.      | SSO 认证中心引导用户至登录页面。                             |

#### 3.4 部署图

单点登录是一个涉及 SSO 认证中心和多个子系统的复杂流程。在这个流程中，子系统必须集成 SSO 客户端，以便与作为服务端的 SSO 认证中心进行通信，交换令牌、验证令牌有效性，并处理注销请求。整个过程实质上是客户端与服务端之间的通信，用下图描述（）：

> <center><img src="pic/img-05.png" width="960"/></center>

<center><font color=silver>img-2.3</font></center>

SSO 认证中心与 SSO 客户端通信方式有多种包括：

- httpClient
- Web Service
- RPC
- Restful API

#### 3.5 实现

SSO 采用`客户端/服务端`架构，具体可以先看 `SSO Client` 与 `SSO Server` 要实现的功能

**SSO Client：**

1. 拦截子系统未登录用户请求，跳转至 SSO 认证中心；
2. 接收并存储 SSO 认证中心发送的令牌；
3. 与 SSO Server 通信，校验令牌的有效性；
4. 建立局部会话；
5. 拦截用户注销请求，向 SSO 认证中心发送注销请求；
6. 接收 SSO 认证中心发出的注销请求，销毁局部会话。

**SSO Server**

1. 验证用户的登录信息；
2. 创建全局会话；
3. 创建授权令牌；
4. 与 SSO Client 通信发送令牌；
5. 校验 SSO Client 令牌有效性；
6. 系统注册；
7. 接收 SSO Client 注销请求，注销所有会话。

<br>

### 4. 微服务

#### 4.1 微服务的好处

**1. 单体项目的缺点**

1. **可扩展性受限：**单体应用通常在可扩展性方面受到限制。因为整个应用程序必须一起扩展。这意味着即使只有一个组件需要更多资源，也必须扩展整个应用程序，这可能会导致资源浪费。
2. **难以维护和更新：**随着时间的推移，单体应用程序往往变得越来越庞大和复杂，难以理解、维护和更新。每次修改都可能引发一项不到的影响。
3. **高风险：**单体应用程序中的一个小错误或故障可能会导致整个应用程序崩溃，因此存在较高的风险。此外，长时间不更新的单体应用可能会收到安全威胁。
4. **技术栈限制：**单体应用程序通常使用相同的技术栈，这可能会限制在项目中使用最新的技术和工具的能力。
5. **团队协作复杂：**单体应用程序的所有组件都在同一个代码库中，这可能导致开发团队之间的冲突和协作问题，尤其是在大型团队中更为突出

**2. 微服务项目的优点：**

1. **高度可扩展性：**微服务架构通过将应用程序拆分成多个小型的服务，每个服务都可以独立地进行扩展。服务的自治性允许我们根据需求对每个服务进行独立的水平扩展，而不必对整个应用程序进行扩展。这种高度扩展性适合应对大规模、高并发的应用场景。
2. **独立开发和部署：**微服务架构将一个大型应用程序拆分成多个小型服务，每个服务都有自己的代码库和开发团队。这种独立性使得不同团队可以并行开发和部署各自的服务，提高了开发效率和灵活性。

<br>

<br>

## 三、分布式

### 1. Dubbo

**1. Dubbo 是什么？**

Dubbo是阿里巴巴开源的基于 Java 的，高性能远程服务调用（RPC，Remote Procedure Call） 分布式服务框架，现已成为 Apache 基金会孵化项目。其核心部分内容包含：
-  **集群容错：**提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。
-  **远程通讯：** 提供对多种基于长连接的 NIO 框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。 
- **自动发现：**基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。

**2. Dubbo 能做什么？**

- **透明化的远程方法调用**，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API 侵入。
- **软负载均衡及容错机制**，可在内网替代 F5 等硬件负载均衡器，降低成本，减少单点。 
- **服务自动注册与发现**，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的 IP 地址，并且能够平滑添加或删除服务提供者。

**3. 默认使用什么通信框架？**

默认（推荐）使用 Netty 框架，除了 Netty，还有 Mina、Grizzly。

**4. 服务调用是阻塞的吗？**

默认是阻塞的，但支持异步调用。

Dubbo 是基于 NIO 的非阻塞实现并行调用，客户端不需要启动多线程即可完成并行调用多个远程服务，相对多线程开销较小，异步调用会返回一个 Future 对象。

异步调用流程图如下：

> <center><img src="pic/img-08.png" width="960"/></center>

<center><font color=silver>img-3.1</font></center>

**5. Dubbo 和 Spring Cloud 有什么区别？**

1）通信方式不同

Dubbo 使用的是 RPC 通信，而 Spring Cloud 使用的是 HTTP RESTFul 方式。

2）组成部分不同

| 组件         | Dubbo         | Spring Cloud                |
| ------------ | ------------- | --------------------------- |
| 服务注册中心 | Zookeeper     | Spring Cloud Netfix Eureka  |
| 服务监控     | Dubbo-monitor | Spring Boot Admin           |
| 断路器       | 不完善        | Spring Cloud Netfix Hystrix |
| 服务网关     | 无            | Spring Cloud Netfix GateWay |
| 分布式配置   | 无            | Spring Cloud Config         |
| 服务跟踪     | 无            | Spring Cloud Sleuth         |
| 消息总线     | 无            | Spring Cloud Bus            |
| 数据流       | 无            | Spring Cloud Stream         |
| 批量任务     | 无            | Spring Cloud Task           |
| ...          | ...           | ...                         |

**4. Dubbo 都支持什么协议，推荐哪种？**

| 协议       | 应用场景                                                     | 优点                                           | 缺点                                                  |
| ---------- | ------------------------------------------------------------ | ---------------------------------------------- | ----------------------------------------------------- |
| dubbo      | 适用于高并发小数据量服务调用，特别是消费者数量远大于提供者的情况 | 减少连接建立和断开的开销，提高性能             | 对网络稳定性要求高，网络问题可能影响连接              |
| rmi        | 适合Java应用间的远程服务调用                                 | 符合 Java 标准，易于Java 应用集成              | 存在安全漏洞，不适合大规模分布式系统                  |
| webservice | 适合需要跨语言交互的系统集成                                 | 支持多种编程语言，具有良好的互操作性           | 性能相对较低，配置相对复杂                            |
| http       | 适用于 Web 服务调用，支持浏览器 JS 调用                      | 基于广泛支持的 HTTP 协议，易于集成             | 不适合高频率或大数据量的调用                          |
| hessian    | 适用于需要高效二进制序列化的场景                             | 序列化和反序列化速度快，适合大数据传输         | 维护多个短连接，提供者端可能面临较大压力              |
| memcached  | 适用于分布式缓存场景，需要快速读写操作                       | 简单高效，读写速度快                           | 主要存储在内存，容量有限，数据易失                    |
| redis      | 适用于需要支持复杂数据结构和持久化的缓存场景                 | 支持多种数据结构，具有持久化选项               | 相比于 Memcached，资源消耗更大                        |
| Thrift     | 适用于需要高效跨语言服务调用的场景                           | 具有高效的二进制数据传输格式，支持多种编程语言 | 需要使用 Thrift 的 IDL 来定义服务接口，增加开发复杂性 |

**5. Dubbo  需要 Web 容器吗？**

不需要，如果硬要用 Web 容器，只会增加复杂性，也浪费资源。

**6. Dubbo 内置了哪几种服务容器？**

- Spring Container
- Jetty Container
- Log4j Container

**7. Dubbo 里面有哪几种节点角色？**

| 节点      | 角色说明                               |
| --------- | -------------------------------------- |
| Provider  | 暴露服务的服务提供方                   |
| Consumer  | 调用远程服务的服务消费方               |
| Registry  | 服务注册与发现的注册中心               |
| Monitor   | 统计服务的调用次数和调用时间的监控中心 |
| Container | 服务运行容器                           |

**8. 服务注册与发现的流程图**

> <center><img src="pic/img-06.png" width="960"/></center>

<center><font color=silver>img-3.2</font></center>

**9. Dubbo默认使用什么注册中心，还有别的选择吗？**

推荐使用 Zookeeper 注册中心，还有 Multicast 注册中心，Redis 注册中心，Simple 注册中心。

ZooKeeper 的节点是通过像树一样的结构来进行维护的，并且每一个节点通过路径来标示以及访问。除此之外，每一个节点还拥有自身的一些信息，包括：数据、数据长度、创建时间、修改时间等等。

**10. Dubbo 有什么配置方式？**

1）Spring 配置方式

2）Java API 配置方式

**11. Dubbo 核心配置有哪些？**

| 配置               | 配置说明     |
| ------------------ | ------------ |
| dubbo: service     | 服务配置     |
| dubbo: reference   | 引用配置     |
| dubbo: protocol    | 协议配置     |
| dubbo: application | 应用配置     |
| dubbo: module      | 模块配置     |
| dubbo: registry    | 注册中心配置 |
| dubbo: monitor     | 监控中心配置 |
| dubbo: provider    | 提供方配置   |
| dubbo: consumer    | 消费方配置   |
| dubbo: method      | 方法配置     |
| dubbo: argument    | 参数配置     |

> 配置之间的关系

> <center><img src="pic/img-07.png" width="960"/></center>

<center><font color=silver>img-3.3</font></center>

**12. 在 Provider 上可以配置的 Consumer 端的属性有哪些？**

1）timeout：方法调用超时

2）retries：失败重试次数，默认重试 2 次

3）loadbalance：负载均衡算法，默认随机

4）actives：消费者端，最大并发调用限制

**13. Dubbo 启动时如果依赖的服务不可用会怎么样？**

`Dubbo 缺省`会在启动时检查依赖的服务是否可用，不可用时会`抛出异常`，阻止 Spring 初始化完成，默认 check="true"，可以通过 `check="false"` 关闭检查。

**14. Dubbo推荐使用什么序列化框架，你知道的还有哪些？**

推荐使用 `Hessian` 序列化，还有Duddo、FastJson、Java 自带序列化。

> Hessian 原理与协议简析：

Hessian 是一种高效的二进制网络传输协议，尽管它遵循 HTTP 协议的基本传输规则，但 Hessian 在数据交换上做了一些优化。

1. 在 Hessian 中，客户端与服务器的通信采用 HTTP POST 方法。这种方式允许在请求中包含更多的数据和信息。
2. Hessian 利用 HTTP 的头部（header）来传递辅助信息，例如安全授权的 token 等。通过 HTTP 头部，我们可以封装安全校验和元数据等信息。Hessian 还提供了基础的校验机制，以确保数据的完整性。
3. Hessian 交互的核心数据，包括调用的方法名和参数列表，会以字节流的形式直接在 POST 请求的正文（body）中发送。这种方式提高了数据传输的效率。
4. 服务器端处理请求后，会将响应数据以字节流的形式直接输出到响应（response）中。这种二进制的响应方式，保证了数据的快速传输和解析。

**15. Dubbo有哪几种集群容错方案，默认是哪种？**

| 集群容错方案      | 说明                                       |
| ----------------- | ------------------------------------------ |
| Failover Cluster  | 失败自动切换，自动重试其他服务器（默认）   |
| Failfast Cluster  | 快速失败，立即报错，只发起一次调用         |
| Failsafe Cluster  | 失败安全，出现异常时，直接忽略             |
| Failback Cluster  | 失败自动恢复，记录失败请求，定时重发       |
| Forking Cluster   | 并行调用多个服务器，只要一个成功即返回     |
| Broadcast Cluster | 广播逐个调用所有提供者，任意一个报错则报错 |

**16. Dubbo有哪几种负载均衡策略，默认是哪种？**

| 负载均衡策略               | 说明                                                         |
| -------------------------- | ------------------------------------------------------------ |
| Random LoadBalance（默认） | 随机，按权重设置随机概率；<br />截面碰撞率高，调用次数越多，分布越均匀。 |
| RoundRobin LoadBalance     | 轮询，按公约后的权重设置轮询比率；<br />存在请求积累的问题。 |
| LeastActive LoadBalance    | 最少活跃调用策略，相同活跃数的随机；<br />解决慢提供者接收更少请求的情况。 |
| ConsistentHash LoadBalance | 一致性 Hash，相同参数的请求总是发到同一提供者；<br />一台机器宕机，可以基于虚拟节点，分摊至其他提供者，避免引起提供者的剧烈变动。 |

**17. 注册了多个同一样的服务，如何测试指定的某一个服务呢？**

可以配置环境点对点直连，绕过注册中心，将以服务接口为单位，忽略注册中心的提供者列表。

**18. Dubbo支持服务多协议吗？**

Dubbo 允许配置多协议，在不同服务上支持不同协议或者同一服务上同时支持多种协议。

**19. 当一个服务接口有多种实现时怎么做？**

当一个接口有多种实现时，可以用 group 属性来分组，服务提供方和消费方都指定同一个 group 即可。

**20. 服务上线怎么兼容旧版本？**

可以用版本号（version）过渡，多个不同版本的服务注册到注册中心，版本号不同的服务相互间不引用。这个和服务分组的概念有一点类似。

**21. Dubbo 可以对结果进行缓存吗？**

可以，Dubbo 提供了声明式缓存，用于加速热门数据的访问速度，以减少用户加缓存的工作量。

**22. 服务提供者能实现失效踢出是什么原理？**

服务失效踢出基于 Zookeeper 的临时节点原理。

**23. 服务上线怎么不影响旧版本？**

采用多版本开发，不影响旧版本。在配置中添加 `version` 来作为版本区分。

### 2. ZooKeeper

**1. 什么是 ZooKeeper？**

- ZooKeeper 主要**服务于分布式系统**，可以用 ZooKeeper 来做：
  - 命名服务
  - 配置管理
  - 集群管理
  - 分布式锁
  - 队列管理

- 使用分布式系统就无法避免对节点管理的问题（需要实时感知节点的状态、对节点进行统一管理等等），而由于这些问题处理起来可能相对麻烦和提高了系统的复杂性，ZooKeeper 作为一个能够**通用**解决这些问题的中间件就应运而生了。
- 其内核为`文件系统`和`通知机制`

**2. ZooKeeper 特性**

ZooKeeper 的数据结构，跟 Unix 文件系统非常类似，可以看做是一颗**树**，每个节点叫做**ZNode**。每一个节点可以通过**路径**来标识，结构图如下：

> <center><img src="pic/img-09.png" width="960"/></center>

<center><font color=silver>img-3.4</font></center>

ZooKeeper 的节点我们称之为 **ZNode**，并且这些节点**都可以设置关联的数据**。Zookeeper 为了保证`高吞吐和低延迟`，在内存中维护了这个树状的目录结构，这种特性使得 Zookeeper **不能用于存放大量的数据**，每个节点的存放数据上限为**1M**。

**3. ZNode 的类型：**

**1）PERSISTENT-持久化目录节点**

客户端与 Zookeeper 断开连接后，该节点依旧存在。

**2）PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点**

客户端与 Zookeeper 断开连接后，该节点依旧存在，只是 Zookeeper 给该节点名称进行顺序编号。

**3）EPHEMERAL-临时目录节点**

客户端与 Zookeeper 断开连接后，该节点被删除。

**4）EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点**

客户端与 Zookeeper 断开连接后，该节点被删除，只是 Zookeeper 给该节点名称进行顺序编号。

**5. Zookeeper 通知机制**

client 端会对某个 ZNode 建立一个 `watcher 事件`，当该 ZNode 发生变化时，这些 client 会收到 Zookeeper 的通知，然后 client 可以根据 ZNode 变化来做出业务上的改变。

**6. Zookeeper 的命名服务（文件系统）**

命名服务是指通过指定的名字来**获取资源**或者**服务的地址**，利用 Zookeeper 创建一个全局的路径，即是**唯一**的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。

**7. Zookeeper 的配置管理（文件系统、通知机制）**

程序分布式部署在不同的机器上，将程序的配置信息放在 **Znode** 下，当有配置发生改变时，也就是 Znode 发生变化时，可以通过改变 Zookeeper 中某个目录节点的内容，利用**watcher**通知给各个客户端，从而更改配置。

**8. Zookeeper 的集群管理（文件系统、通知机制）**

所谓集群管理无在乎两点：**是否有机器退出和加入、选举master**。

**1）机器的退出和加入**

所有机器约定在父目录下**创建临时目录节点**，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 Zookeeper 的连接断开，其所创建的临时目录节点被删除，**所有其他机器都收到通知：某个兄弟目录被删除**。新机器加入也是类似，**所有其他机器都收到通知：新兄弟目录加入**。

**2）选举master**

**所有机器创建临时顺序编号目录节点时，选取编号最小的机器作为 master**。

**9. Zookeeper 分布式锁（文件系统、通知机制）**

有了 Zookeeper 的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是**保持独占**，另一个是**控制时序**。

**1）保持独占**

将 Zookeeper 上的一个 **ZNode 看作是一把锁**，通过 CreateZNode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的 distribute_lock 节点就释放出锁。

**2）控制时序**

假设 /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选 master 一样，**编号最小的获得锁**，用完删除，依次方便。

**10. 获取分布式锁的流程**

> <center><img src="pic/img-10.png" width="960"/></center>

<center><font color=silver>img-3.5</font></center>

使用 Zookeeper 实现分布式锁时，客户端首先在指定的 "locker" 节点下创建一个临时顺序节点。这一过程通过调用 `createNode` 方法完成，该方法在 "locker" 节点下生成一个具有唯一序号的临时节点。

随后，客户端调用 `getChildren("locker")` 方法来检索 "locker" 节点下的所有子节点，但在此步骤中不设置任何 Watcher，以避免不必要的事件通知。

客户端获取到子节点列表后，会检查自己创建的节点序号是否为列表中的最小值。如果是，客户端便成功获取了锁。如果不是，客户端则需要进一步操作。客户端会找到序号比自己小的最小节点，并对其调用`exist()`方法，同时注册一个事件监听器。这个监听器的作用是在该节点被删除时接收通知。

一旦被关注的节点被删除，客户端的事件监听器将触发，客户端随即再次检查自己的节点是否已成为"locker"子节点中序号最小的节点。如果是，客户端便成功获取了锁；如果不是，客户端需要重复上述步骤，继续寻找并关注比自己节点序号小的下一个节点。

在整个过程中，客户端需要进行一系列的逻辑判断，以确保正确地处理节点的创建、比较、监听和删除等操作。这个过程虽然复杂，但通过 Zookeeper 的有序节点和事件监听机制，可以有效地实现分布式锁的管理和同步。

> <center><img src="pic/img-11.png" width="960"/></center>

<center><font color=silver>img-3.6</font></center>

**11. Zookeeper 对列管理（文件系统、通知机制）**

队列的定义：

1）同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。
2）队列按照 FIFO 方式进行入队和出队操作。

两种类型的队列：

1）在约定目录下创建临时目录节点，监听节点数目是约定的数目。
2）与分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。在特定的目录下创建 **PERSISTENT_SEQUENTIAL** 节点，创建成功时 **Watcher** 通知等待的队列，队列删除**序列号最小的节点**用以消费。此场景下 Zookeeper 的 ZNode 用于消息存储，ZNode 存储的数据就是消息队列中的消息内容，SEQUENTIAL 序列号就是消息的编号，按序取出即可。由于创建的节点是持久化的，所以**不必担心队列消息的丢失问题**。

**12. Zookeeper 数据复制（文件系统、通知机制）**

Zookeeper 为一个集群提供一致的数据服务，它在所有机器间做数据复制。

**1）数据复制的好处：**

1. 容错：一个节点出错，不致于让整个系统停止工作，别的节点可以接管它的工作；

2. 提高系统的扩展能力 ：把负载分布到多个节点上，或者增加节点来提高系统的负载能力；

3. 提高性能：让**客户端本地访问就近的节点，提高用户访问速度**

**2）从客户端读写访问的透明度来看，数据复制集群系统分下面两种：**

1. 写主 (WriteMaster)：对数据的**修改提交给指定的节点**。读无此限制，可以读取任何一个节点。这种情况下客户端需要对读与写进行区别，俗称**读写分离**；



## Reference

- [2024年吃透经典Java面试题200问，7天学完，让你面试少走99%弯路！！](https://www.bilibili.com/video/BV1kt4y1o7QV/?spm_id_from=333.337.search-card.all.click&vd_source=ecb044e8a1b950cef5efdc6f9ea34cbb)
- [Java面试+Java后端技术学习指南](https://github.com/hello-java-maker/JavaInterview?tab=readme-ov-file#并发)
- [Java基础面试16问](https://mp.weixin.qq.com/s/-xFSHf7Gz3FUcafTJUIGWQ)
- [MySQL 高频面试题，都在这了](https://mp.weixin.qq.com/s/KFCkvfF84l6Eu43CH_TmXA)
- [什么是存储引擎以及MySQL常见的三种数据库存储引擎-CSDN博客](https://blog.csdn.net/RitaAndWakaka/article/details/118059592)
- [前后端分离架构概述-CSDN博客](https://blog.csdn.net/fuzhongmin05/article/details/81591072)
- [前后端分离之JWT用户认证 - 简书](https://www.jianshu.com/p/180a870a308a)
- [老司机总结的12条 SQL 优化方案](https://mp.weixin.qq.com/s/7QuASKTpXOm54CgLiHqEJg)
- [MySQL事务，这篇文章就够了](https://sihai.blog.csdn.net/article/details/102815801)
- [我去！原来单点登录这么简单，这下糗大了！](https://mp.weixin.qq.com/s/LGnUueNC-EuoxiF-8b-TeQ)
- [史上最全 40 道 Dubbo 面试题及答案，看完碾压面试官！](https://mp.weixin.qq.com/s/PdWRHgm83XwPYP08KnkIsw)
- [dubbo 面试18问（含答案）](https://mp.weixin.qq.com/s/Kz0s9K3J9Lpvh37oP_CtCA)
- [什么是ZooKeeper？](https://mp.weixin.qq.com/s/i2_c4A0146B7Ev8QnofbfQ)
- [负载均衡 - zookeeper面试题 - 个人文章 - SegmentFault 思否](https://segmentfault.com/a/1190000014479433)


